{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T12:08:32.338787Z",
     "iopub.status.busy": "2025-12-28T12:08:32.338576Z",
     "iopub.status.idle": "2025-12-28T12:08:32.502903Z",
     "shell.execute_reply": "2025-12-28T12:08:32.501949Z",
     "shell.execute_reply.started": "2025-12-28T12:08:32.338745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 28 12:08:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T00:35:48.249566Z",
     "iopub.status.busy": "2025-12-29T00:35:48.249175Z",
     "iopub.status.idle": "2025-12-29T00:35:48.382933Z",
     "shell.execute_reply": "2025-12-29T00:35:48.380353Z",
     "shell.execute_reply.started": "2025-12-29T00:35:48.249539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTrW8ZGvWNhF",
    "outputId": "bc63eee1-8594-4d3b-d92b-8647e5bfba9d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/KapKr21/fl-project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-30T10:19:05.943641Z",
     "iopub.status.busy": "2025-12-30T10:19:05.943272Z",
     "iopub.status.idle": "2025-12-30T10:19:06.063789Z",
     "shell.execute_reply": "2025-12-30T10:19:06.062594Z",
     "shell.execute_reply.started": "2025-12-30T10:19:05.943609Z"
    },
    "id": "sZGDTv-FXhkq",
    "outputId": "b0aa9e7d-4340-47c7-ce6f-7021a13c0673",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl-project  model_56000.zip  model_60000.zip\n",
      "/kaggle/working/fl-project\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "%cd fl-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-28T12:10:09.612556Z",
     "iopub.status.busy": "2025-12-28T12:10:09.611872Z",
     "iopub.status.idle": "2025-12-28T12:10:10.528051Z",
     "shell.execute_reply": "2025-12-28T12:10:10.527132Z",
     "shell.execute_reply.started": "2025-12-28T12:10:09.612522Z"
    },
    "id": "8UciM4haYPVh",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5d073425-b7df-450d-849a-8607e6820d6e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples  LICENSE.md  loralib  README.md  SECURITY.md  setup.py\n",
      "On branch lora-fine-tuning\n",
      "Your branch is ahead of 'origin/lora-fine-tuning' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   examples/NLG/eval/e2e/pycocoevalcap/meteor/data/paraphrase-en.gz\u001b[m\n",
      "\t\u001b[31mdeleted:    examples/NLU/docs/source/contributing.md\u001b[m\n",
      "\t\u001b[31mdeleted:    examples/NLU/docs/source/examples.md\u001b[m\n",
      "\t\u001b[31mdeleted:    examples/NLU/docs/source/notebooks.md\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/benchmarking/run_benchmark.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/benchmarking/run_benchmark_tf.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/language-modeling/run_clm.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/language-modeling/run_mlm.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/language-modeling/run_mlm_flax.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/language-modeling/run_plm.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/pytorch-lightning/run_glue.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/pytorch-lightning/run_ner.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/pytorch-lightning/run_pos.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/run_camembert.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/run_chinese_ref.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/run_language_modeling.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/run_openai_gpt.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/run_swag.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/run_transfo_xl.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/convert_model_to_fp16.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/download_wmt.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/finetune_trainer.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/minify_dataset.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/pack_dataset.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/run_distributed_eval.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/run_eval.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/run_eval_search.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/save_len_file.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/save_randomly_initialized_model.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/seq2seq/test_data/fsmt/build-eval-data.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/token-classification/run.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/token-classification/run_chunk.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/legacy/token-classification/run_pos.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/multiple-choice/run_swag.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/multiple-choice/run_tf_multiple_choice.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/question-answering/run_qa.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/question-answering/run_qa_beam_search.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/question-answering/run_tf_squad.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/bert-loses-patience/README.md\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/bert-loses-patience/run_glue_with_pabee.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/deebert/entropy_eval.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/deebert/eval_deebert.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/deebert/train_deebert.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/performer/full_script.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/performer/sanity_script.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/rag/finetune_rag.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/rag/finetune_rag_ray.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/convert_pl_checkpoint_to_hf.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/distil_marian_enro_teacher.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/distil_marian_no_teacher.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/distillation.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/dynamic_bs_example.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/finetune.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/finetune.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/finetune_bart_tiny.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/finetune_pegasus_xsum.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/finetune_t5.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/run_eval.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/train_distilbart_cnn.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/train_distilbart_xsum.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/seq2seq-distillation/train_mbart_cc25_enro.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/wav2vec2/finetune_base_100.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/wav2vec2/finetune_large_lv60_100.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/research_projects/wav2vec2/run_asr.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/seq2seq/run_summarization.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/seq2seq/run_translation.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/text-classification/run_glue.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/text-classification/run_tf_glue.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/text-classification/run_tf_text_classification.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/text-classification/run_xnli.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/text-generation/run_generation.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/token-classification/run.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/examples/token-classification/run_ner.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/convert-allenai-wmt16.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/convert-allenai-wmt19.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/convert-facebook-wmt19.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/eval-allenai-wmt16.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/eval-allenai-wmt19.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/eval-facebook-wmt19.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/fsmt-make-super-tiny-model.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/fsmt-make-tiny-model.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/gen-card-allenai-wmt16.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/gen-card-allenai-wmt19.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/gen-card-facebook-wmt19.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/fsmt/tests-to-run.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/pegasus/build_test_sample_spm_no_bos.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/scripts/tatoeba/upload_models.sh\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/__init__.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/configuration_utils.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/convert_pytorch_checkpoint_to_tf2.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/convert_slow_tokenizers_checkpoints_to_fast.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/convert_tf_hub_seq_to_seq_bert_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/modeling_utils.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/albert/modeling_albert.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/bart/modeling_bart.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/bert/modeling_bert.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/bert_generation/modeling_bert_generation.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/blenderbot/modeling_blenderbot.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/convbert/modeling_convbert.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/distilbert/modeling_distilbert.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/led/modeling_led.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/longformer/modeling_longformer.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/m2m_100/modeling_m2m_100.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/marian/modeling_marian.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/mbart/modeling_mbart.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/pegasus/modeling_pegasus.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/reformer/configuration_reformer.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/reformer/modeling_reformer.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/speech_to_text/modeling_speech_to_text.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/wav2vec2/modeling_wav2vec2.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/xlm/modeling_xlm.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/models/xlnet/modeling_xlnet.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/pipelines/__init__.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/src/transformers/trainer.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/templates/adding_a_new_example_script/{{cookiecutter.directory_name}}/run_{{cookiecutter.example_shortcut}}.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_{{cookiecutter.lowercase_modelname}}.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/tests/test_modeling_bert.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/tests/test_modeling_bert_generation.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/tests/test_modeling_common.py\u001b[m\n",
      "\t\u001b[31mmodified:   examples/NLU/tests/test_modeling_ibert.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mexamples/NLG/pretrained_checkpoints/\u001b[m\n",
      "\t\u001b[31mexamples/NLG/src/__pycache__/\u001b[m\n",
      "\t\u001b[31mexamples/NLG/state.db\u001b[m\n",
      "\t\u001b[31mexamples/NLG/trained_models/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "* \u001b[32mlora-fine-tuning\u001b[m\n",
      "  main\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!git status\n",
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T12:10:21.614374Z",
     "iopub.status.busy": "2025-12-28T12:10:21.614055Z",
     "iopub.status.idle": "2025-12-28T12:10:42.221719Z",
     "shell.execute_reply": "2025-12-28T12:10:42.220944Z",
     "shell.execute_reply.started": "2025-12-28T12:10:21.614345Z"
    },
    "id": "Wav7qQi-Y2pC",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install -U pip\n",
    "!pip -q install spacy tqdm tensorboard progress loralib\n",
    "!pip -q install -U \"transformers>=4.41,<6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-30T10:18:57.976215Z",
     "iopub.status.busy": "2025-12-30T10:18:57.975451Z",
     "iopub.status.idle": "2025-12-30T10:18:58.095443Z",
     "shell.execute_reply": "2025-12-30T10:18:58.094339Z",
     "shell.execute_reply.started": "2025-12-30T10:18:57.976159Z"
    },
    "id": "50VpFQHBa9No",
    "outputId": "686615ac-cbff-4e5c-d38e-1915019d0566",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'examples/NLG'\n",
      "/kaggle/working\n",
      "bash: download_pretrained_checkpoints.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%cd examples/NLG\n",
    "!bash download_pretrained_checkpoints.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T12:11:08.643916Z",
     "iopub.status.busy": "2025-12-28T12:11:08.643579Z",
     "iopub.status.idle": "2025-12-28T12:11:10.762380Z",
     "shell.execute_reply": "2025-12-28T12:11:10.761642Z",
     "shell.execute_reply.started": "2025-12-28T12:11:08.643884Z"
    },
    "id": "6gKmdd7Tblc8",
    "outputId": "f8eeb0a9-6506-463e-db5a-57b0da556094",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1T5S3lJpcdyu",
    "outputId": "65ff4a02-a15c-4984-fff5-c1c261b7c317",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!bash create_datasets.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RZKvHbosc6eu",
    "outputId": "893b94b7-c524-4ed3-e98f-80fd7da9df74",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%cd eval\n",
    "!bash download_evalscript.sh\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T12:11:22.038302Z",
     "iopub.status.busy": "2025-12-28T12:11:22.037616Z",
     "iopub.status.idle": "2025-12-28T12:11:22.043077Z",
     "shell.execute_reply": "2025-12-28T12:11:22.042286Z",
     "shell.execute_reply.started": "2025-12-28T12:11:22.038267Z"
    },
    "id": "bFrnX8d3d1Nt",
    "outputId": "d3d3d401-f687-40c8-a862-6619a2a3f606",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
     ]
    }
   ],
   "source": [
    "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-OCVguqSe3lY",
    "outputId": "50acffc5-5299-4b69-8662-4e88a4c3750e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node=1 src/gpt2_ft.py \\\n",
    "  --train_data ./data/e2e/train.jsonl \\\n",
    "  --valid_data ./data/e2e/valid.jsonl \\\n",
    "  --train_batch_size 2 \\\n",
    "  --grad_acc 4 \\\n",
    "  --valid_batch_size 1 \\\n",
    "  --seq_len 512 \\\n",
    "  --model_card gpt2.md \\\n",
    "  --init_checkpoint ./pretrained_checkpoints/gpt2-medium-pytorch_model.bin \\\n",
    "  --platform local \\\n",
    "  --clip 0.0 \\\n",
    "  --lr 0.0002 \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --correct_bias \\\n",
    "  --adam_beta2 0.999 \\\n",
    "  --scheduler linear \\\n",
    "  --warmup_step 2000 \\\n",
    "  --max_epoch 2 \\\n",
    "  --save_interval 4000 \\\n",
    "  --lora_dim 4 \\\n",
    "  --lora_alpha 32 \\\n",
    "  --lora_dropout 0.1 \\\n",
    "  --label_smooth 0.1 \\\n",
    "  --work_dir ./trained_models/GPT2_M/e2e \\\n",
    "  --random_seed 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T10:19:16.680644Z",
     "iopub.status.busy": "2025-12-30T10:19:16.680279Z",
     "iopub.status.idle": "2025-12-30T10:19:16.911314Z",
     "shell.execute_reply": "2025-12-30T10:19:16.910302Z",
     "shell.execute_reply.started": "2025-12-30T10:19:16.680612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples  LICENSE.md  loralib  README.md  SECURITY.md  setup.py\n",
      "/kaggle/working/fl-project/examples/NLG\n",
      "CODE_OF_CONDUCT.md\t\t    eval\t\t    SECURITY.md\n",
      "create_datasets.sh\t\t    figures\t\t    src\n",
      "data\t\t\t\t    LICENSE\t\t    state.db\n",
      "download_pretrained_checkpoints.sh  pretrained_checkpoints  trained_models\n",
      "e2e_pred.txt\t\t\t    README.md\t\t    vocab\n",
      "e2e_ref.txt\t\t\t    requirement.txt\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "%cd examples/NLG\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node=1 src/gpt2_beam.py \\\n",
    "  --data ./data/e2e/test.jsonl \\\n",
    "  --batch_size 1 \\\n",
    "  --seq_len 512 \\\n",
    "  --eval_len 64 \\\n",
    "  --model_card gpt2.md \\\n",
    "  --init_checkpoint ./trained_models/GPT2_M/e2e/model.42062.pt \\\n",
    "  --platform local \\\n",
    "  --lora_dim 4 \\\n",
    "  --lora_alpha 32 \\\n",
    "  --beam 10 \\\n",
    "  --length_penalty 0.8 \\\n",
    "  --no_repeat_ngram_size 4 \\\n",
    "  --repetition_penalty 1.0 \\\n",
    "  --eos_token_id 628 \\\n",
    "  --work_dir ./trained_models/GPT2_M/e2e \\\n",
    "  --output_file predict.42062.b10p08r4.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T12:13:15.827748Z",
     "iopub.status.busy": "2025-12-28T12:13:15.826931Z",
     "iopub.status.idle": "2025-12-28T12:13:15.946006Z",
     "shell.execute_reply": "2025-12-28T12:13:15.945253Z",
     "shell.execute_reply.started": "2025-12-28T12:13:15.827711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4693 trained_models/GPT2_M/e2e/predict.42062.b10p08r4.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l trained_models/GPT2_M/e2e/predict.42062.b10p08r4.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T12:14:03.804817Z",
     "iopub.status.busy": "2025-12-28T12:14:03.804184Z",
     "iopub.status.idle": "2025-12-28T12:14:08.688657Z",
     "shell.execute_reply": "2025-12-28T12:14:08.687961Z",
     "shell.execute_reply.started": "2025-12-28T12:14:03.804782Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/fl-project/examples/NLG/src/gpt2_decode.py:50: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  sent = ' '.join(re.split('(\\W)', sent))\n",
      "unique refer dict 630\n"
     ]
    }
   ],
   "source": [
    "!python src/gpt2_decode.py \\\n",
    "  --vocab ./vocab \\\n",
    "  --sample_file ./trained_models/GPT2_M/e2e/predict.42062.b10p08r4.jsonl \\\n",
    "  --input_file ./data/e2e/test_formatted.jsonl \\\n",
    "  --output_ref_file e2e_ref.txt \\\n",
    "  --output_pred_file e2e_pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T12:15:15.230847Z",
     "iopub.status.busy": "2025-12-28T12:15:15.230083Z",
     "iopub.status.idle": "2025-12-28T12:15:15.347159Z",
     "shell.execute_reply": "2025-12-28T12:15:15.346441Z",
     "shell.execute_reply.started": "2025-12-28T12:15:15.230813Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5323 e2e_ref.txt\n",
      "   630 e2e_pred.txt\n",
      "  5953 total\n"
     ]
    }
   ],
   "source": [
    "!wc -l e2e_ref.txt e2e_pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T12:18:43.726549Z",
     "iopub.status.busy": "2025-12-28T12:18:43.726192Z",
     "iopub.status.idle": "2025-12-28T12:19:03.554202Z",
     "shell.execute_reply": "2025-12-28T12:19:03.553452Z",
     "shell.execute_reply.started": "2025-12-28T12:18:43.726518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/fl-project/examples/NLG/eval/e2e/measure_scores.py:208: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  elif re.search('\\.[ct]sv$', sys_file, re.I):\n",
      "/kaggle/working/fl-project/examples/NLG/eval/e2e/measure_scores.py:216: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  if re.search('\\.[ct]sv$', ref_file, re.I):\n",
      "Running MS-COCO evaluator...\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 132573 tokens at 368342.79 tokens per second.\n",
      "PTBTokenizer tokenized 18540 tokens at 122113.38 tokens per second.\n",
      "setting up scorers...\n",
      "computing METEOR score...\n",
      "METEOR: 0.455\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.694\n",
      "computing CIDEr score...\n",
      "CIDEr: 2.406\n",
      "Running Py-MTEval metrics...\n",
      "SCORES:\n",
      "==============\n",
      "BLEU: 0.6759\n",
      "NIST: 8.6072\n",
      "METEOR: 0.4546\n",
      "ROUGE_L: 0.6938\n",
      "CIDEr: 2.4059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python eval/e2e/measure_scores.py e2e_ref.txt e2e_pred.txt -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T12:44:08.181009Z",
     "iopub.status.busy": "2025-12-28T12:44:08.180260Z",
     "iopub.status.idle": "2025-12-28T12:44:10.520953Z",
     "shell.execute_reply": "2025-12-28T12:44:10.519967Z",
     "shell.execute_reply.started": "2025-12-28T12:44:08.180972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Retraining with more steps i.e. 100000+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "execution_failed": "2025-12-29T00:08:31.728Z",
     "iopub.execute_input": "2025-12-28T12:55:20.323915Z",
     "iopub.status.busy": "2025-12-28T12:55:20.323048Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myrank: 0 local_rank: 0 device_count: 1 world_size: 1\n",
      "====================================================================================================\n",
      "        - platform : local\n",
      "        - local_rank : 0\n",
      "        - rank : 0\n",
      "        - device : cuda:0\n",
      "        - world_size : 1\n",
      "        - random_seed : 110\n",
      "        - lr : 0.0002\n",
      "        - weight_decay : 0.01\n",
      "        - correct_bias : True\n",
      "        - adam_epislon : 1e-06\n",
      "        - no_decay_bias : False\n",
      "        - adam_beta1 : 0.9\n",
      "        - adam_beta2 : 0.999\n",
      "        - scheduler : linear\n",
      "        - max_step : None\n",
      "        - max_epoch : 5\n",
      "        - warmup_step : 2000\n",
      "        - i_steps : 0\n",
      "        - i_lrs : 0.00025\n",
      "        - train_data : ./data/e2e/train.jsonl\n",
      "        - valid_data : ./data/e2e/valid.jsonl\n",
      "        - train_batch_size : 2\n",
      "        - valid_batch_size : 1\n",
      "        - grad_acc : 4\n",
      "        - clip : 0.0\n",
      "        - seq_len : 512\n",
      "        - model_card : gpt2.md\n",
      "        - init_checkpoint : ./pretrained_checkpoints/gpt2-medium-pytorch_model.bin\n",
      "        - fp16 : False\n",
      "        - log_interval : 100\n",
      "        - eval_interval : 2000\n",
      "        - save_interval : 4000\n",
      "        - work_dir : ./trained_models/GPT2_M/e2e_seed110_full\n",
      "        - lora_dim : 4\n",
      "        - lora_alpha : 32\n",
      "        - obj : clm\n",
      "        - lora_dropout : 0.1\n",
      "        - label_smooth : 0.1\n",
      "        - roll_interval : -1\n",
      "        - roll_lr : 1e-05\n",
      "        - roll_step : 100\n",
      "        - eval_epoch : 1\n",
      "        - dist : <module 'torch.distributed' from '/usr/local/lib/python3.12/dist-packages/torch/distributed/__init__.py'>\n",
      "====================================================================================================\n",
      "Experiment dir : ./trained_models/GPT2_M/e2e_seed110_full\n",
      "loading model pretrained weight.\n",
      "set max_step: 105155\n",
      "start to train the model................ 1\n",
      "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "/kaggle/working/fl-project/examples/NLG/src/optimizer.py:117: UserWarning: This overload of addcdiv_ is deprecated:\n",
      "\taddcdiv_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcdiv_(Tensor tensor1, Tensor tensor2, *, Number value = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1691.)\n",
      "  p.data.addcdiv_(-step_size, exp_avg, denom)\n",
      "| epoch   1 step      100 |    100 batches | lr 1e-05 | ms/batch 434.56 | loss  6.01 | avg loss  5.86 | ppl 351.66\n",
      "| epoch   1 step      200 |    200 batches | lr 2e-05 | ms/batch 430.63 | loss  5.49 | avg loss  5.78 | ppl 323.95\n",
      "| epoch   1 step      300 |    300 batches | lr 3e-05 | ms/batch 430.78 | loss  5.44 | avg loss  5.67 | ppl 290.15\n",
      "| epoch   1 step      400 |    400 batches | lr 4e-05 | ms/batch 430.95 | loss  5.08 | avg loss  5.20 | ppl 180.75\n",
      "| epoch   1 step      500 |    500 batches | lr 5e-05 | ms/batch 430.72 | loss  4.50 | avg loss  4.33 | ppl 75.66\n",
      "| epoch   1 step      600 |    600 batches | lr 6e-05 | ms/batch 430.67 | loss  3.89 | avg loss  3.81 | ppl 45.32\n",
      "| epoch   1 step      700 |    700 batches | lr 7e-05 | ms/batch 431.06 | loss  3.96 | avg loss  3.52 | ppl 33.80\n",
      "| epoch   1 step      800 |    800 batches | lr 8e-05 | ms/batch 430.73 | loss  3.14 | avg loss  3.23 | ppl 25.36\n",
      "| epoch   1 step      900 |    900 batches | lr 9e-05 | ms/batch 430.60 | loss  3.48 | avg loss  3.20 | ppl 24.52\n",
      "| epoch   1 step     1000 |   1000 batches | lr 0.0001 | ms/batch 432.36 | loss  2.90 | avg loss  3.08 | ppl 21.78\n",
      "| epoch   1 step     1100 |   1100 batches | lr 0.00011 | ms/batch 432.62 | loss  2.73 | avg loss  3.05 | ppl 21.02\n",
      "| epoch   1 step     1200 |   1200 batches | lr 0.00012 | ms/batch 432.78 | loss  2.74 | avg loss  3.05 | ppl 21.02\n",
      "| epoch   1 step     1300 |   1300 batches | lr 0.00013 | ms/batch 433.37 | loss  3.53 | avg loss  2.99 | ppl 19.98\n",
      "| epoch   1 step     1400 |   1400 batches | lr 0.00014 | ms/batch 432.76 | loss  2.83 | avg loss  3.01 | ppl 20.35\n",
      "| epoch   1 step     1500 |   1500 batches | lr 0.00015 | ms/batch 431.20 | loss  3.74 | avg loss  2.97 | ppl 19.41\n",
      "| epoch   1 step     1600 |   1600 batches | lr 0.00016 | ms/batch 429.59 | loss  2.61 | avg loss  2.92 | ppl 18.54\n",
      "| epoch   1 step     1700 |   1700 batches | lr 0.00017 | ms/batch 428.87 | loss  2.28 | avg loss  2.91 | ppl 18.27\n",
      "| epoch   1 step     1800 |   1800 batches | lr 0.00018 | ms/batch 429.78 | loss  2.37 | avg loss  2.87 | ppl 17.71\n",
      "| epoch   1 step     1900 |   1900 batches | lr 0.00019 | ms/batch 430.55 | loss  2.27 | avg loss  2.81 | ppl 16.57\n",
      "| epoch   1 step     2000 |   2000 batches | lr 0.0002 | ms/batch 430.43 | loss  3.09 | avg loss  2.84 | ppl 17.11\n",
      "/usr/local/lib/python3.12/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "eval samples: 0 loss: tensor(1.3940, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0949, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.8880, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.2223, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.5101, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.8622, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.3895, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.6381, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(2.1031, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.7570, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.1797, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.8507, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.9759, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(1.0240, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5492, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.8990, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(1.2124, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.9894, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(1.0425, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.9521, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.8779, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.2499, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.6540, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.4402, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5539, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.8240, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.5580, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.6103, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.9637, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.2438, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.8176, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.4701, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.2375, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5742, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(1.2680, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.8568, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(3.0829, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.2240, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.9797, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.3755, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.7136, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.5891, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.8435, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9135, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0965, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.2355, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3571, device='cuda:0')\n",
      "average loss 1.4913636084314283\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   1 at step     2000 | time: 475.55s | valid loss  1.49 | valid ppl  4.44 | best ppl  4.44 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "/usr/local/lib/python3.12/dist-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "  warnings.warn(  # warn only once\n",
      "| epoch   1 step     2100 |   2100 batches | lr 0.0002 | ms/batch 5185.19 | loss  2.96 | avg loss  2.88 | ppl 17.88\n",
      "| epoch   1 step     2200 |   2200 batches | lr 0.0002 | ms/batch 430.77 | loss  2.44 | avg loss  2.90 | ppl 18.21\n",
      "| epoch   1 step     2300 |   2300 batches | lr 0.000199 | ms/batch 431.41 | loss  3.42 | avg loss  2.86 | ppl 17.53\n",
      "| epoch   1 step     2400 |   2400 batches | lr 0.000199 | ms/batch 432.02 | loss  2.10 | avg loss  2.88 | ppl 17.75\n",
      "| epoch   1 step     2500 |   2500 batches | lr 0.000199 | ms/batch 432.19 | loss  2.66 | avg loss  2.73 | ppl 15.35\n",
      "| epoch   1 step     2600 |   2600 batches | lr 0.000199 | ms/batch 432.54 | loss  2.48 | avg loss  2.90 | ppl 18.20\n",
      "| epoch   1 step     2700 |   2700 batches | lr 0.000199 | ms/batch 431.41 | loss  2.53 | avg loss  2.77 | ppl 15.92\n",
      "| epoch   1 step     2800 |   2800 batches | lr 0.000198 | ms/batch 430.74 | loss  2.88 | avg loss  2.82 | ppl 16.83\n",
      "| epoch   1 step     2900 |   2900 batches | lr 0.000198 | ms/batch 429.62 | loss  2.67 | avg loss  2.82 | ppl 16.71\n",
      "| epoch   1 step     3000 |   3000 batches | lr 0.000198 | ms/batch 427.95 | loss  2.69 | avg loss  2.75 | ppl 15.72\n",
      "| epoch   1 step     3100 |   3100 batches | lr 0.000198 | ms/batch 427.94 | loss  3.00 | avg loss  2.72 | ppl 15.20\n",
      "| epoch   1 step     3200 |   3200 batches | lr 0.000198 | ms/batch 427.91 | loss  2.29 | avg loss  2.78 | ppl 16.10\n",
      "| epoch   1 step     3300 |   3300 batches | lr 0.000197 | ms/batch 428.91 | loss  2.15 | avg loss  2.80 | ppl 16.52\n",
      "| epoch   1 step     3400 |   3400 batches | lr 0.000197 | ms/batch 428.56 | loss  2.84 | avg loss  2.78 | ppl 16.17\n",
      "| epoch   1 step     3500 |   3500 batches | lr 0.000197 | ms/batch 428.72 | loss  2.48 | avg loss  2.70 | ppl 14.91\n",
      "| epoch   1 step     3600 |   3600 batches | lr 0.000197 | ms/batch 428.57 | loss  2.90 | avg loss  2.83 | ppl 16.97\n",
      "| epoch   1 step     3700 |   3700 batches | lr 0.000197 | ms/batch 429.07 | loss  2.47 | avg loss  2.82 | ppl 16.74\n",
      "| epoch   1 step     3800 |   3800 batches | lr 0.000197 | ms/batch 428.87 | loss  2.96 | avg loss  2.75 | ppl 15.63\n",
      "| epoch   1 step     3900 |   3900 batches | lr 0.000196 | ms/batch 429.47 | loss  2.96 | avg loss  2.74 | ppl 15.46\n",
      "| epoch   1 step     4000 |   4000 batches | lr 0.000196 | ms/batch 429.18 | loss  3.05 | avg loss  2.76 | ppl 15.80\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.4000.pt\n",
      "eval samples: 0 loss: tensor(1.4106, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1267, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.6976, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.2508, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.4495, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.8034, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.2448, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.6335, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.9423, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.6927, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.0604, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.7065, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.7809, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.8665, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5275, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7950, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9510, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.9486, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.8182, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6978, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.6832, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0917, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.6372, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2666, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5939, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.6773, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.3316, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4764, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.8576, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.1037, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.7076, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.1953, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1053, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5751, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(1.1896, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.8992, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.8619, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.1951, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.8028, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1356, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.5067, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.4719, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.5718, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9591, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0031, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.1160, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.5212, device='cuda:0')\n",
      "average loss 1.4085443277958116\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   2 at step     4000 | time: 474.21s | valid loss  1.41 | valid ppl  4.09 | best ppl  4.09 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step     4100 |   4100 batches | lr 0.000196 | ms/batch 5170.91 | loss  4.06 | avg loss  2.76 | ppl 15.72\n",
      "| epoch   1 step     4200 |   4200 batches | lr 0.000196 | ms/batch 428.22 | loss  2.49 | avg loss  2.77 | ppl 15.95\n",
      "| epoch   1 step     4300 |   4300 batches | lr 0.000196 | ms/batch 428.49 | loss  2.61 | avg loss  2.77 | ppl 15.94\n",
      "| epoch   1 step     4400 |   4400 batches | lr 0.000195 | ms/batch 428.61 | loss  2.78 | avg loss  2.77 | ppl 15.99\n",
      "| epoch   1 step     4500 |   4500 batches | lr 0.000195 | ms/batch 428.24 | loss  3.20 | avg loss  2.80 | ppl 16.51\n",
      "| epoch   1 step     4600 |   4600 batches | lr 0.000195 | ms/batch 428.09 | loss  2.46 | avg loss  2.71 | ppl 15.04\n",
      "| epoch   1 step     4700 |   4700 batches | lr 0.000195 | ms/batch 428.89 | loss  3.50 | avg loss  2.75 | ppl 15.64\n",
      "| epoch   1 step     4800 |   4800 batches | lr 0.000195 | ms/batch 428.46 | loss  2.80 | avg loss  2.77 | ppl 15.89\n",
      "| epoch   1 step     4900 |   4900 batches | lr 0.000194 | ms/batch 428.11 | loss  2.61 | avg loss  2.70 | ppl 14.85\n",
      "| epoch   1 step     5000 |   5000 batches | lr 0.000194 | ms/batch 428.29 | loss  2.51 | avg loss  2.79 | ppl 16.30\n",
      "| epoch   1 step     5100 |   5100 batches | lr 0.000194 | ms/batch 427.97 | loss  2.85 | avg loss  2.73 | ppl 15.36\n",
      "| epoch   1 step     5200 |   5200 batches | lr 0.000194 | ms/batch 427.79 | loss  2.53 | avg loss  2.75 | ppl 15.68\n",
      "| epoch   1 step     5300 |   5300 batches | lr 0.000194 | ms/batch 428.47 | loss  2.31 | avg loss  2.73 | ppl 15.27\n",
      "| epoch   1 step     5400 |   5400 batches | lr 0.000193 | ms/batch 428.11 | loss  2.88 | avg loss  2.72 | ppl 15.18\n",
      "| epoch   1 step     5500 |   5500 batches | lr 0.000193 | ms/batch 427.75 | loss  2.51 | avg loss  2.70 | ppl 14.81\n",
      "| epoch   1 step     5600 |   5600 batches | lr 0.000193 | ms/batch 427.85 | loss  4.01 | avg loss  2.74 | ppl 15.53\n",
      "| epoch   1 step     5700 |   5700 batches | lr 0.000193 | ms/batch 427.72 | loss  2.52 | avg loss  2.80 | ppl 16.39\n",
      "| epoch   1 step     5800 |   5800 batches | lr 0.000193 | ms/batch 427.99 | loss  2.35 | avg loss  2.74 | ppl 15.43\n",
      "| epoch   1 step     5900 |   5900 batches | lr 0.000192 | ms/batch 428.84 | loss  2.07 | avg loss  2.68 | ppl 14.63\n",
      "| epoch   1 step     6000 |   6000 batches | lr 0.000192 | ms/batch 428.95 | loss  2.51 | avg loss  2.68 | ppl 14.63\n",
      "eval samples: 0 loss: tensor(1.3190, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0533, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.6066, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.0246, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.3719, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7254, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1970, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.4436, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.9069, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.6334, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9251, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6141, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.7730, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.8287, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5464, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7580, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9655, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.9445, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.7592, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6629, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.6447, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0513, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.5572, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.3002, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5120, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.6114, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.4017, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4825, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7658, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0592, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6709, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2458, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0034, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4784, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.9532, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.8726, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.8991, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.1815, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.6043, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1611, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.4654, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.2935, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4581, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9059, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0027, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.1683, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.4424, device='cuda:0')\n",
      "average loss 1.339926163442688\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   3 at step     6000 | time: 474.77s | valid loss  1.34 | valid ppl  3.82 | best ppl  3.82 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step     6100 |   6100 batches | lr 0.000192 | ms/batch 5176.37 | loss  2.53 | avg loss  2.74 | ppl 15.43\n",
      "| epoch   1 step     6200 |   6200 batches | lr 0.000192 | ms/batch 428.35 | loss  2.37 | avg loss  2.70 | ppl 14.87\n",
      "| epoch   1 step     6300 |   6300 batches | lr 0.000192 | ms/batch 428.45 | loss  3.07 | avg loss  2.67 | ppl 14.47\n",
      "| epoch   1 step     6400 |   6400 batches | lr 0.000191 | ms/batch 429.09 | loss  2.71 | avg loss  2.71 | ppl 14.98\n",
      "| epoch   1 step     6500 |   6500 batches | lr 0.000191 | ms/batch 429.21 | loss  2.86 | avg loss  2.73 | ppl 15.41\n",
      "| epoch   1 step     6600 |   6600 batches | lr 0.000191 | ms/batch 429.19 | loss  3.70 | avg loss  2.74 | ppl 15.51\n",
      "| epoch   1 step     6700 |   6700 batches | lr 0.000191 | ms/batch 429.39 | loss  2.24 | avg loss  2.71 | ppl 15.09\n",
      "| epoch   1 step     6800 |   6800 batches | lr 0.000191 | ms/batch 429.17 | loss  2.40 | avg loss  2.70 | ppl 14.93\n",
      "| epoch   1 step     6900 |   6900 batches | lr 0.00019 | ms/batch 429.45 | loss  2.74 | avg loss  2.70 | ppl 14.82\n",
      "| epoch   1 step     7000 |   7000 batches | lr 0.00019 | ms/batch 429.17 | loss  2.74 | avg loss  2.67 | ppl 14.51\n",
      "| epoch   1 step     7100 |   7100 batches | lr 0.00019 | ms/batch 429.18 | loss  2.44 | avg loss  2.70 | ppl 14.87\n",
      "| epoch   1 step     7200 |   7200 batches | lr 0.00019 | ms/batch 429.03 | loss  2.67 | avg loss  2.73 | ppl 15.33\n",
      "| epoch   1 step     7300 |   7300 batches | lr 0.00019 | ms/batch 429.08 | loss  2.63 | avg loss  2.72 | ppl 15.16\n",
      "| epoch   1 step     7400 |   7400 batches | lr 0.00019 | ms/batch 429.05 | loss  2.34 | avg loss  2.66 | ppl 14.24\n",
      "| epoch   1 step     7500 |   7500 batches | lr 0.000189 | ms/batch 429.15 | loss  2.47 | avg loss  2.70 | ppl 14.89\n",
      "| epoch   1 step     7600 |   7600 batches | lr 0.000189 | ms/batch 429.14 | loss  2.38 | avg loss  2.68 | ppl 14.59\n",
      "| epoch   1 step     7700 |   7700 batches | lr 0.000189 | ms/batch 429.13 | loss  2.49 | avg loss  2.68 | ppl 14.65\n",
      "| epoch   1 step     7800 |   7800 batches | lr 0.000189 | ms/batch 429.04 | loss  3.43 | avg loss  2.74 | ppl 15.55\n",
      "| epoch   1 step     7900 |   7900 batches | lr 0.000189 | ms/batch 429.01 | loss  3.17 | avg loss  2.66 | ppl 14.28\n",
      "| epoch   1 step     8000 |   8000 batches | lr 0.000188 | ms/batch 429.15 | loss  2.82 | avg loss  2.68 | ppl 14.60\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.8000.pt\n",
      "eval samples: 0 loss: tensor(1.3631, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0939, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.5081, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.2081, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.3283, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7761, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1749, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.4198, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.9012, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.6435, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.0750, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6247, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.7722, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.8258, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.8453, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7437, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.8213, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7763, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6277, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.7864, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.5171, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1496, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.4676, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2822, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5680, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.4240, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2914, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4317, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7973, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0691, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6870, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3859, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1701, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5366, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.8797, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.8161, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.8005, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.3233, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5972, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1467, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.5022, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.3472, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4811, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8031, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9519, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.0896, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.4656, device='cuda:0')\n",
      "average loss 1.3330017146845794\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   4 at step     8000 | time: 475.03s | valid loss  1.33 | valid ppl  3.79 | best ppl  3.79 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step     8100 |   8100 batches | lr 0.000188 | ms/batch 5178.69 | loss  2.46 | avg loss  2.67 | ppl 14.49\n",
      "| epoch   1 step     8200 |   8200 batches | lr 0.000188 | ms/batch 428.11 | loss  2.57 | avg loss  2.58 | ppl 13.22\n",
      "| epoch   1 step     8300 |   8300 batches | lr 0.000188 | ms/batch 428.05 | loss  2.27 | avg loss  2.61 | ppl 13.58\n",
      "| epoch   1 step     8400 |   8400 batches | lr 0.000188 | ms/batch 427.85 | loss  2.69 | avg loss  2.67 | ppl 14.43\n",
      "| epoch   1 step     8500 |   8500 batches | lr 0.000187 | ms/batch 427.71 | loss  2.70 | avg loss  2.72 | ppl 15.23\n",
      "| epoch   1 step     8600 |   8600 batches | lr 0.000187 | ms/batch 427.69 | loss  3.08 | avg loss  2.68 | ppl 14.63\n",
      "| epoch   1 step     8700 |   8700 batches | lr 0.000187 | ms/batch 427.57 | loss  2.94 | avg loss  2.68 | ppl 14.61\n",
      "| epoch   1 step     8800 |   8800 batches | lr 0.000187 | ms/batch 427.74 | loss  2.44 | avg loss  2.71 | ppl 15.09\n",
      "| epoch   1 step     8900 |   8900 batches | lr 0.000187 | ms/batch 427.55 | loss  3.22 | avg loss  2.75 | ppl 15.64\n",
      "| epoch   1 step     9000 |   9000 batches | lr 0.000186 | ms/batch 427.60 | loss  2.91 | avg loss  2.65 | ppl 14.22\n",
      "| epoch   1 step     9100 |   9100 batches | lr 0.000186 | ms/batch 427.75 | loss  2.30 | avg loss  2.60 | ppl 13.44\n",
      "| epoch   1 step     9200 |   9200 batches | lr 0.000186 | ms/batch 427.88 | loss  2.61 | avg loss  2.68 | ppl 14.51\n",
      "| epoch   1 step     9300 |   9300 batches | lr 0.000186 | ms/batch 428.01 | loss  2.67 | avg loss  2.73 | ppl 15.26\n",
      "| epoch   1 step     9400 |   9400 batches | lr 0.000186 | ms/batch 428.10 | loss  2.63 | avg loss  2.67 | ppl 14.50\n",
      "| epoch   1 step     9500 |   9500 batches | lr 0.000185 | ms/batch 428.15 | loss  4.12 | avg loss  2.68 | ppl 14.56\n",
      "| epoch   1 step     9600 |   9600 batches | lr 0.000185 | ms/batch 428.05 | loss  2.45 | avg loss  2.72 | ppl 15.15\n",
      "| epoch   1 step     9700 |   9700 batches | lr 0.000185 | ms/batch 428.23 | loss  2.18 | avg loss  2.69 | ppl 14.68\n",
      "| epoch   1 step     9800 |   9800 batches | lr 0.000185 | ms/batch 428.55 | loss  2.67 | avg loss  2.60 | ppl 13.46\n",
      "| epoch   1 step     9900 |   9900 batches | lr 0.000185 | ms/batch 428.65 | loss  2.63 | avg loss  2.70 | ppl 14.84\n",
      "| epoch   1 step    10000 |  10000 batches | lr 0.000184 | ms/batch 428.67 | loss  2.54 | avg loss  2.63 | ppl 13.90\n",
      "eval samples: 0 loss: tensor(1.3413, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1052, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.5241, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.2118, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2914, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7421, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1624, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.4747, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.7592, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4695, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.0280, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6605, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.7184, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7908, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5876, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.8101, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.8350, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.8410, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6386, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.8238, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.5193, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.2414, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.4799, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.3494, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4866, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.3569, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.4109, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4206, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7426, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0448, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6797, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2695, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1763, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5215, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.8601, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7683, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7913, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.1596, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.6204, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1444, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3734, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.3338, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3844, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8935, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0439, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.1006, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.4981, device='cuda:0')\n",
      "average loss 1.3215930665753883\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   5 at step    10000 | time: 474.51s | valid loss  1.32 | valid ppl  3.75 | best ppl  3.75 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step    10100 |  10100 batches | lr 0.000184 | ms/batch 5172.36 | loss  2.45 | avg loss  2.72 | ppl 15.14\n",
      "| epoch   1 step    10200 |  10200 batches | lr 0.000184 | ms/batch 427.75 | loss  3.25 | avg loss  2.62 | ppl 13.77\n",
      "| epoch   1 step    10300 |  10300 batches | lr 0.000184 | ms/batch 427.83 | loss  2.18 | avg loss  2.64 | ppl 13.96\n",
      "| epoch   1 step    10400 |  10400 batches | lr 0.000184 | ms/batch 428.13 | loss  2.81 | avg loss  2.58 | ppl 13.15\n",
      "| epoch   1 step    10500 |  10500 batches | lr 0.000184 | ms/batch 428.05 | loss  3.39 | avg loss  2.64 | ppl 14.04\n",
      "| epoch   1 step    10600 |  10600 batches | lr 0.000183 | ms/batch 428.08 | loss  3.00 | avg loss  2.59 | ppl 13.37\n",
      "| epoch   1 step    10700 |  10700 batches | lr 0.000183 | ms/batch 428.18 | loss  2.40 | avg loss  2.64 | ppl 14.03\n",
      "| epoch   1 step    10800 |  10800 batches | lr 0.000183 | ms/batch 427.60 | loss  3.10 | avg loss  2.60 | ppl 13.49\n",
      "| epoch   1 step    10900 |  10900 batches | lr 0.000183 | ms/batch 427.85 | loss  2.33 | avg loss  2.71 | ppl 14.96\n",
      "| epoch   1 step    11000 |  11000 batches | lr 0.000183 | ms/batch 427.36 | loss  2.45 | avg loss  2.64 | ppl 14.00\n",
      "| epoch   1 step    11100 |  11100 batches | lr 0.000182 | ms/batch 427.75 | loss  2.68 | avg loss  2.69 | ppl 14.75\n",
      "| epoch   1 step    11200 |  11200 batches | lr 0.000182 | ms/batch 427.49 | loss  2.87 | avg loss  2.67 | ppl 14.47\n",
      "| epoch   1 step    11300 |  11300 batches | lr 0.000182 | ms/batch 427.74 | loss  2.88 | avg loss  2.61 | ppl 13.65\n",
      "| epoch   1 step    11400 |  11400 batches | lr 0.000182 | ms/batch 427.74 | loss  2.38 | avg loss  2.58 | ppl 13.15\n",
      "| epoch   1 step    11500 |  11500 batches | lr 0.000182 | ms/batch 427.61 | loss  2.31 | avg loss  2.67 | ppl 14.48\n",
      "| epoch   1 step    11600 |  11600 batches | lr 0.000181 | ms/batch 427.76 | loss  2.82 | avg loss  2.60 | ppl 13.41\n",
      "| epoch   1 step    11700 |  11700 batches | lr 0.000181 | ms/batch 427.86 | loss  2.73 | avg loss  2.63 | ppl 13.90\n",
      "| epoch   1 step    11800 |  11800 batches | lr 0.000181 | ms/batch 427.66 | loss  2.61 | avg loss  2.66 | ppl 14.26\n",
      "| epoch   1 step    11900 |  11900 batches | lr 0.000181 | ms/batch 427.82 | loss  2.46 | avg loss  2.64 | ppl 13.98\n",
      "| epoch   1 step    12000 |  12000 batches | lr 0.000181 | ms/batch 427.82 | loss  2.89 | avg loss  2.59 | ppl 13.39\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.12000.pt\n",
      "eval samples: 0 loss: tensor(1.3676, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0660, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.4673, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.0979, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2520, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6765, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.2505, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3378, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.7511, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4935, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.0286, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6602, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6894, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.8019, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.7623, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.8040, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.8420, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.8567, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.7453, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6266, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4376, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1201, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.4261, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1956, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4809, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.4012, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2015, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4157, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7535, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0219, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6229, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3083, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1047, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5101, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.7197, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7449, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7700, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.1512, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5293, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2068, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.4415, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.2943, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3872, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.7996, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9892, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.0103, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3871, device='cuda:0')\n",
      "average loss 1.2886595364583477\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   6 at step    12000 | time: 474.42s | valid loss  1.29 | valid ppl  3.63 | best ppl  3.63 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step    12100 |  12100 batches | lr 0.00018 | ms/batch 5172.26 | loss  2.59 | avg loss  2.60 | ppl 13.51\n",
      "| epoch   1 step    12200 |  12200 batches | lr 0.00018 | ms/batch 427.65 | loss  2.20 | avg loss  2.64 | ppl 14.04\n",
      "| epoch   1 step    12300 |  12300 batches | lr 0.00018 | ms/batch 427.84 | loss  2.97 | avg loss  2.65 | ppl 14.15\n",
      "| epoch   1 step    12400 |  12400 batches | lr 0.00018 | ms/batch 427.68 | loss  3.03 | avg loss  2.67 | ppl 14.37\n",
      "| epoch   1 step    12500 |  12500 batches | lr 0.00018 | ms/batch 427.54 | loss  2.20 | avg loss  2.64 | ppl 14.03\n",
      "| epoch   1 step    12600 |  12600 batches | lr 0.000179 | ms/batch 427.63 | loss  2.94 | avg loss  2.68 | ppl 14.59\n",
      "| epoch   1 step    12700 |  12700 batches | lr 0.000179 | ms/batch 427.64 | loss  2.20 | avg loss  2.59 | ppl 13.39\n",
      "| epoch   1 step    12800 |  12800 batches | lr 0.000179 | ms/batch 427.62 | loss  3.09 | avg loss  2.65 | ppl 14.11\n",
      "| epoch   1 step    12900 |  12900 batches | lr 0.000179 | ms/batch 427.55 | loss  2.40 | avg loss  2.60 | ppl 13.44\n",
      "| epoch   1 step    13000 |  13000 batches | lr 0.000179 | ms/batch 427.69 | loss  2.96 | avg loss  2.61 | ppl 13.59\n",
      "| epoch   1 step    13100 |  13100 batches | lr 0.000178 | ms/batch 427.77 | loss  2.29 | avg loss  2.69 | ppl 14.77\n",
      "| epoch   1 step    13200 |  13200 batches | lr 0.000178 | ms/batch 427.88 | loss  2.96 | avg loss  2.69 | ppl 14.66\n",
      "| epoch   1 step    13300 |  13300 batches | lr 0.000178 | ms/batch 427.90 | loss  2.69 | avg loss  2.63 | ppl 13.83\n",
      "| epoch   1 step    13400 |  13400 batches | lr 0.000178 | ms/batch 427.82 | loss  2.14 | avg loss  2.62 | ppl 13.76\n",
      "| epoch   1 step    13500 |  13500 batches | lr 0.000178 | ms/batch 427.96 | loss  2.46 | avg loss  2.62 | ppl 13.72\n",
      "| epoch   1 step    13600 |  13600 batches | lr 0.000178 | ms/batch 427.93 | loss  2.81 | avg loss  2.66 | ppl 14.34\n",
      "| epoch   1 step    13700 |  13700 batches | lr 0.000177 | ms/batch 427.48 | loss  2.03 | avg loss  2.65 | ppl 14.15\n",
      "| epoch   1 step    13800 |  13800 batches | lr 0.000177 | ms/batch 427.54 | loss  2.29 | avg loss  2.56 | ppl 12.97\n",
      "| epoch   1 step    13900 |  13900 batches | lr 0.000177 | ms/batch 427.64 | loss  2.87 | avg loss  2.61 | ppl 13.53\n",
      "| epoch   1 step    14000 |  14000 batches | lr 0.000177 | ms/batch 427.83 | loss  3.19 | avg loss  2.69 | ppl 14.79\n",
      "eval samples: 0 loss: tensor(1.4418, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0908, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.4837, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.1880, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.3396, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7416, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.3180, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3750, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.7329, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.5785, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9756, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5985, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.7162, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.8179, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.7003, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7816, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9656, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.8325, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6833, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6143, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4699, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1484, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.4439, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.3027, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5077, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2956, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2888, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4600, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7548, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0260, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.7099, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3090, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1264, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5030, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.7353, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.8052, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7477, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.1213, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.6398, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2174, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.4494, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1935, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4251, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8370, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9685, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.0294, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.4747, device='cuda:0')\n",
      "average loss 1.301012957060378\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   7 at step    14000 | time: 474.41s | valid loss  1.30 | valid ppl  3.67 | best ppl  3.63 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step    14100 |  14100 batches | lr 0.000177 | ms/batch 5171.91 | loss  2.09 | avg loss  2.66 | ppl 14.35\n",
      "| epoch   1 step    14200 |  14200 batches | lr 0.000176 | ms/batch 427.79 | loss  2.89 | avg loss  2.65 | ppl 14.10\n",
      "| epoch   1 step    14300 |  14300 batches | lr 0.000176 | ms/batch 428.07 | loss  2.41 | avg loss  2.63 | ppl 13.92\n",
      "| epoch   1 step    14400 |  14400 batches | lr 0.000176 | ms/batch 427.94 | loss  2.58 | avg loss  2.63 | ppl 13.85\n",
      "| epoch   1 step    14500 |  14500 batches | lr 0.000176 | ms/batch 428.17 | loss  3.79 | avg loss  2.69 | ppl 14.72\n",
      "| epoch   1 step    14600 |  14600 batches | lr 0.000176 | ms/batch 428.01 | loss  2.11 | avg loss  2.61 | ppl 13.65\n",
      "| epoch   1 step    14700 |  14700 batches | lr 0.000175 | ms/batch 428.17 | loss  3.14 | avg loss  2.64 | ppl 14.04\n",
      "| epoch   1 step    14800 |  14800 batches | lr 0.000175 | ms/batch 427.88 | loss  2.55 | avg loss  2.61 | ppl 13.61\n",
      "| epoch   1 step    14900 |  14900 batches | lr 0.000175 | ms/batch 429.00 | loss  3.03 | avg loss  2.55 | ppl 12.86\n",
      "| epoch   1 step    15000 |  15000 batches | lr 0.000175 | ms/batch 428.31 | loss  2.61 | avg loss  2.59 | ppl 13.39\n",
      "| epoch   1 step    15100 |  15100 batches | lr 0.000175 | ms/batch 428.26 | loss  3.08 | avg loss  2.66 | ppl 14.32\n",
      "| epoch   1 step    15200 |  15200 batches | lr 0.000174 | ms/batch 427.76 | loss  3.63 | avg loss  2.64 | ppl 14.00\n",
      "| epoch   1 step    15300 |  15300 batches | lr 0.000174 | ms/batch 427.98 | loss  2.63 | avg loss  2.70 | ppl 14.87\n",
      "| epoch   1 step    15400 |  15400 batches | lr 0.000174 | ms/batch 427.87 | loss  2.57 | avg loss  2.65 | ppl 14.16\n",
      "| epoch   1 step    15500 |  15500 batches | lr 0.000174 | ms/batch 427.87 | loss  2.48 | avg loss  2.59 | ppl 13.39\n",
      "| epoch   1 step    15600 |  15600 batches | lr 0.000174 | ms/batch 427.71 | loss  2.49 | avg loss  2.62 | ppl 13.80\n",
      "| epoch   1 step    15700 |  15700 batches | lr 0.000173 | ms/batch 427.83 | loss  2.27 | avg loss  2.61 | ppl 13.67\n",
      "| epoch   1 step    15800 |  15800 batches | lr 0.000173 | ms/batch 427.84 | loss  3.05 | avg loss  2.63 | ppl 13.86\n",
      "| epoch   1 step    15900 |  15900 batches | lr 0.000173 | ms/batch 427.74 | loss  2.31 | avg loss  2.58 | ppl 13.22\n",
      "| epoch   1 step    16000 |  16000 batches | lr 0.000173 | ms/batch 427.53 | loss  2.47 | avg loss  2.62 | ppl 13.80\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.16000.pt\n",
      "eval samples: 0 loss: tensor(1.3134, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0913, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.4493, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.0531, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.3335, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7084, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1130, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.4331, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5976, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.6516, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8880, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6171, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6617, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7293, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.7549, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7903, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9364, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.8375, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6331, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6442, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4489, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0810, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3588, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2306, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4520, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.3534, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.3325, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4519, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7230, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9145, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6398, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3425, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1029, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4392, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.6961, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7306, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7049, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.1740, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5898, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1290, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.4127, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1841, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3521, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9187, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9512, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9940, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.4313, device='cuda:0')\n",
      "average loss 1.265185667087056\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   8 at step    16000 | time: 474.31s | valid loss  1.27 | valid ppl  3.54 | best ppl  3.54 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step    16100 |  16100 batches | lr 0.000173 | ms/batch 5170.60 | loss  2.93 | avg loss  2.57 | ppl 13.06\n",
      "| epoch   1 step    16200 |  16200 batches | lr 0.000172 | ms/batch 427.54 | loss  2.69 | avg loss  2.59 | ppl 13.27\n",
      "| epoch   1 step    16300 |  16300 batches | lr 0.000172 | ms/batch 427.53 | loss  2.27 | avg loss  2.64 | ppl 14.01\n",
      "| epoch   1 step    16400 |  16400 batches | lr 0.000172 | ms/batch 427.51 | loss  2.28 | avg loss  2.56 | ppl 12.91\n",
      "| epoch   1 step    16500 |  16500 batches | lr 0.000172 | ms/batch 427.51 | loss  2.79 | avg loss  2.63 | ppl 13.94\n",
      "| epoch   1 step    16600 |  16600 batches | lr 0.000172 | ms/batch 427.31 | loss  2.75 | avg loss  2.69 | ppl 14.78\n",
      "| epoch   1 step    16700 |  16700 batches | lr 0.000171 | ms/batch 428.08 | loss  2.00 | avg loss  2.56 | ppl 12.94\n",
      "| epoch   1 step    16800 |  16800 batches | lr 0.000171 | ms/batch 427.94 | loss  2.65 | avg loss  2.63 | ppl 13.81\n",
      "| epoch   1 step    16900 |  16900 batches | lr 0.000171 | ms/batch 427.83 | loss  2.47 | avg loss  2.67 | ppl 14.50\n",
      "| epoch   1 step    17000 |  17000 batches | lr 0.000171 | ms/batch 427.67 | loss  2.88 | avg loss  2.67 | ppl 14.37\n",
      "| epoch   1 step    17100 |  17100 batches | lr 0.000171 | ms/batch 427.68 | loss  2.35 | avg loss  2.61 | ppl 13.61\n",
      "| epoch   1 step    17300 |  17300 batches | lr 0.00017 | ms/batch 427.66 | loss  2.45 | avg loss  2.53 | ppl 12.54\n",
      "| epoch   1 step    17400 |  17400 batches | lr 0.00017 | ms/batch 427.97 | loss  2.76 | avg loss  2.59 | ppl 13.38\n",
      "| epoch   1 step    17500 |  17500 batches | lr 0.00017 | ms/batch 427.78 | loss  3.04 | avg loss  2.63 | ppl 13.86\n",
      "| epoch   1 step    17600 |  17600 batches | lr 0.00017 | ms/batch 427.80 | loss  2.64 | avg loss  2.59 | ppl 13.28\n",
      "| epoch   1 step    17700 |  17700 batches | lr 0.00017 | ms/batch 427.84 | loss  2.39 | avg loss  2.58 | ppl 13.22\n",
      "| epoch   1 step    17800 |  17800 batches | lr 0.000169 | ms/batch 427.77 | loss  3.00 | avg loss  2.58 | ppl 13.26\n",
      "| epoch   1 step    17900 |  17900 batches | lr 0.000169 | ms/batch 427.81 | loss  2.40 | avg loss  2.60 | ppl 13.47\n",
      "| epoch   1 step    18000 |  18000 batches | lr 0.000169 | ms/batch 428.16 | loss  2.54 | avg loss  2.61 | ppl 13.63\n",
      "eval samples: 0 loss: tensor(1.3770, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0373, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3915, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9941, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1973, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6693, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1559, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2679, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.6624, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.5421, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.0141, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6168, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.7178, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7229, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.8424, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7269, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(1.0662, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.8075, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6422, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5494, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4056, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1277, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.4724, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1676, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4782, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.3615, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.4079, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3794, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7374, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0429, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6655, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3332, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1041, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4438, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.6561, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7598, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7432, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.0534, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5968, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1395, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3863, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.2821, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3600, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8991, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9742, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9552, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3454, device='cuda:0')\n",
      "average loss 1.26127745586205\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval   9 at step    18000 | time: 474.94s | valid loss  1.26 | valid ppl  3.53 | best ppl  3.53 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step    18100 |  18100 batches | lr 0.000169 | ms/batch 5179.06 | loss  2.31 | avg loss  2.51 | ppl 12.35\n",
      "| epoch   1 step    18200 |  18200 batches | lr 0.000169 | ms/batch 429.77 | loss  3.05 | avg loss  2.61 | ppl 13.61\n",
      "| epoch   1 step    18300 |  18300 batches | lr 0.000168 | ms/batch 429.52 | loss  2.35 | avg loss  2.63 | ppl 13.83\n",
      "| epoch   1 step    18400 |  18400 batches | lr 0.000168 | ms/batch 429.62 | loss  2.37 | avg loss  2.61 | ppl 13.56\n",
      "| epoch   1 step    18500 |  18500 batches | lr 0.000168 | ms/batch 429.69 | loss  2.16 | avg loss  2.62 | ppl 13.70\n",
      "| epoch   1 step    18600 |  18600 batches | lr 0.000168 | ms/batch 429.72 | loss  2.75 | avg loss  2.67 | ppl 14.51\n",
      "| epoch   1 step    18700 |  18700 batches | lr 0.000168 | ms/batch 429.52 | loss  3.15 | avg loss  2.62 | ppl 13.74\n",
      "| epoch   1 step    18800 |  18800 batches | lr 0.000167 | ms/batch 429.75 | loss  2.38 | avg loss  2.61 | ppl 13.66\n",
      "| epoch   1 step    18900 |  18900 batches | lr 0.000167 | ms/batch 429.91 | loss  2.65 | avg loss  2.57 | ppl 13.05\n",
      "| epoch   1 step    19000 |  19000 batches | lr 0.000167 | ms/batch 429.76 | loss  2.27 | avg loss  2.58 | ppl 13.23\n",
      "| epoch   1 step    19100 |  19100 batches | lr 0.000167 | ms/batch 429.84 | loss  3.12 | avg loss  2.67 | ppl 14.45\n",
      "| epoch   1 step    19200 |  19200 batches | lr 0.000167 | ms/batch 430.07 | loss  2.70 | avg loss  2.58 | ppl 13.18\n",
      "| epoch   1 step    19300 |  19300 batches | lr 0.000166 | ms/batch 430.11 | loss  2.46 | avg loss  2.71 | ppl 14.99\n",
      "| epoch   1 step    19400 |  19400 batches | lr 0.000166 | ms/batch 429.79 | loss  2.59 | avg loss  2.66 | ppl 14.27\n",
      "| epoch   1 step    19500 |  19500 batches | lr 0.000166 | ms/batch 429.90 | loss  2.75 | avg loss  2.56 | ppl 12.91\n",
      "| epoch   1 step    19600 |  19600 batches | lr 0.000166 | ms/batch 429.82 | loss  2.16 | avg loss  2.57 | ppl 13.07\n",
      "| epoch   1 step    19700 |  19700 batches | lr 0.000166 | ms/batch 429.44 | loss  2.58 | avg loss  2.57 | ppl 13.11\n",
      "| epoch   1 step    19800 |  19800 batches | lr 0.000165 | ms/batch 429.48 | loss  2.35 | avg loss  2.62 | ppl 13.72\n",
      "| epoch   1 step    19900 |  19900 batches | lr 0.000165 | ms/batch 429.82 | loss  2.73 | avg loss  2.58 | ppl 13.17\n",
      "| epoch   1 step    20000 |  20000 batches | lr 0.000165 | ms/batch 429.43 | loss  2.61 | avg loss  2.61 | ppl 13.54\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.20000.pt\n",
      "eval samples: 0 loss: tensor(1.4208, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0563, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.4585, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(1.0075, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2523, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7119, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1989, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3156, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.6347, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4946, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.0240, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5987, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6782, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7513, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6595, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.8063, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9420, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.8165, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6382, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5488, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4628, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1141, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3609, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1954, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5100, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1708, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2407, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4713, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7793, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0531, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6623, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3018, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1744, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5108, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.6691, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7559, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7350, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.0340, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.6167, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2651, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3866, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1883, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3275, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9279, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9745, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9686, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3046, device='cuda:0')\n",
      "average loss 1.260321936072552\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  10 at step    20000 | time: 475.75s | valid loss  1.26 | valid ppl  3.53 | best ppl  3.53 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   1 step    20100 |  20100 batches | lr 0.000165 | ms/batch 5187.32 | loss  2.51 | avg loss  2.62 | ppl 13.75\n",
      "| epoch   1 step    20200 |  20200 batches | lr 0.000165 | ms/batch 429.71 | loss  2.65 | avg loss  2.62 | ppl 13.77\n",
      "| epoch   1 step    20300 |  20300 batches | lr 0.000165 | ms/batch 429.56 | loss  2.67 | avg loss  2.66 | ppl 14.36\n",
      "| epoch   1 step    20400 |  20400 batches | lr 0.000164 | ms/batch 429.65 | loss  2.77 | avg loss  2.65 | ppl 14.20\n",
      "| epoch   1 step    20500 |  20500 batches | lr 0.000164 | ms/batch 429.64 | loss  2.68 | avg loss  2.60 | ppl 13.50\n",
      "| epoch   1 step    20600 |  20600 batches | lr 0.000164 | ms/batch 429.71 | loss  2.33 | avg loss  2.64 | ppl 14.03\n",
      "| epoch   1 step    20700 |  20700 batches | lr 0.000164 | ms/batch 429.69 | loss  3.24 | avg loss  2.56 | ppl 12.99\n",
      "| epoch   1 step    20800 |  20800 batches | lr 0.000164 | ms/batch 429.43 | loss  2.53 | avg loss  2.61 | ppl 13.57\n",
      "| epoch   1 step    20900 |  20900 batches | lr 0.000163 | ms/batch 429.83 | loss  2.66 | avg loss  2.59 | ppl 13.27\n",
      "| epoch   1 step    21000 |  21000 batches | lr 0.000163 | ms/batch 429.76 | loss  2.90 | avg loss  2.65 | ppl 14.22\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.21031.pt\n",
      "start to train the model................ 2\n",
      "| epoch   2 step    21100 |     69 batches | lr 0.000163 | ms/batch 296.73 | loss  2.43 | avg loss  2.61 | ppl 13.55\n",
      "| epoch   2 step    21200 |    169 batches | lr 0.000163 | ms/batch 429.82 | loss  2.39 | avg loss  2.55 | ppl 12.87\n",
      "| epoch   2 step    21300 |    269 batches | lr 0.000163 | ms/batch 429.79 | loss  2.21 | avg loss  2.59 | ppl 13.29\n",
      "| epoch   2 step    21400 |    369 batches | lr 0.000162 | ms/batch 429.61 | loss  2.36 | avg loss  2.62 | ppl 13.75\n",
      "| epoch   2 step    21500 |    469 batches | lr 0.000162 | ms/batch 429.75 | loss  2.78 | avg loss  2.63 | ppl 13.84\n",
      "| epoch   2 step    21600 |    569 batches | lr 0.000162 | ms/batch 429.77 | loss  2.48 | avg loss  2.55 | ppl 12.87\n",
      "| epoch   2 step    21700 |    669 batches | lr 0.000162 | ms/batch 430.09 | loss  2.56 | avg loss  2.59 | ppl 13.32\n",
      "| epoch   2 step    21800 |    769 batches | lr 0.000162 | ms/batch 430.06 | loss  2.78 | avg loss  2.64 | ppl 13.96\n",
      "| epoch   2 step    21900 |    869 batches | lr 0.000161 | ms/batch 429.58 | loss  3.21 | avg loss  2.57 | ppl 13.13\n",
      "| epoch   2 step    22000 |    969 batches | lr 0.000161 | ms/batch 429.43 | loss  2.56 | avg loss  2.54 | ppl 12.72\n",
      "eval samples: 0 loss: tensor(1.3474, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1426, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.4224, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9481, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2635, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6844, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1448, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3442, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.6300, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4514, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(1.0155, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5626, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6669, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7197, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6450, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7899, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9165, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7788, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6100, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5980, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4333, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0724, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3748, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2925, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5125, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2391, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2740, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4228, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7424, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9744, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6501, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2898, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0677, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4267, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.5955, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7898, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7590, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9914, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5550, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1306, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3376, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1681, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3921, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8540, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0089, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9543, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3702, device='cuda:0')\n",
      "average loss 1.2489317821734265\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  11 at step    22000 | time: 475.77s | valid loss  1.25 | valid ppl  3.49 | best ppl  3.49 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    22100 |   1069 batches | lr 0.000161 | ms/batch 5187.29 | loss  2.53 | avg loss  2.64 | ppl 14.00\n",
      "| epoch   2 step    22200 |   1169 batches | lr 0.000161 | ms/batch 429.63 | loss  2.46 | avg loss  2.55 | ppl 12.80\n",
      "| epoch   2 step    22300 |   1269 batches | lr 0.000161 | ms/batch 429.59 | loss  2.45 | avg loss  2.60 | ppl 13.52\n",
      "| epoch   2 step    22400 |   1369 batches | lr 0.00016 | ms/batch 429.64 | loss  2.58 | avg loss  2.61 | ppl 13.60\n",
      "| epoch   2 step    22500 |   1469 batches | lr 0.00016 | ms/batch 429.45 | loss  2.81 | avg loss  2.60 | ppl 13.40\n",
      "| epoch   2 step    22600 |   1569 batches | lr 0.00016 | ms/batch 429.66 | loss  2.79 | avg loss  2.58 | ppl 13.17\n",
      "| epoch   2 step    22700 |   1669 batches | lr 0.00016 | ms/batch 429.73 | loss  2.56 | avg loss  2.55 | ppl 12.82\n",
      "| epoch   2 step    22800 |   1769 batches | lr 0.00016 | ms/batch 429.75 | loss  3.21 | avg loss  2.58 | ppl 13.24\n",
      "| epoch   2 step    22900 |   1869 batches | lr 0.000159 | ms/batch 429.50 | loss  2.46 | avg loss  2.58 | ppl 13.26\n",
      "| epoch   2 step    23000 |   1969 batches | lr 0.000159 | ms/batch 429.58 | loss  2.47 | avg loss  2.62 | ppl 13.76\n",
      "| epoch   2 step    23100 |   2069 batches | lr 0.000159 | ms/batch 429.49 | loss  2.09 | avg loss  2.58 | ppl 13.26\n",
      "| epoch   2 step    23200 |   2169 batches | lr 0.000159 | ms/batch 429.59 | loss  2.33 | avg loss  2.60 | ppl 13.47\n",
      "| epoch   2 step    23300 |   2269 batches | lr 0.000159 | ms/batch 429.64 | loss  2.58 | avg loss  2.59 | ppl 13.40\n",
      "| epoch   2 step    23400 |   2369 batches | lr 0.000159 | ms/batch 429.27 | loss  2.50 | avg loss  2.58 | ppl 13.24\n",
      "| epoch   2 step    23500 |   2469 batches | lr 0.000158 | ms/batch 429.66 | loss  2.57 | avg loss  2.57 | ppl 13.04\n",
      "| epoch   2 step    23600 |   2569 batches | lr 0.000158 | ms/batch 429.64 | loss  2.58 | avg loss  2.54 | ppl 12.70\n",
      "| epoch   2 step    23700 |   2669 batches | lr 0.000158 | ms/batch 429.71 | loss  2.26 | avg loss  2.58 | ppl 13.16\n",
      "| epoch   2 step    23800 |   2769 batches | lr 0.000158 | ms/batch 429.45 | loss  1.95 | avg loss  2.56 | ppl 12.91\n",
      "| epoch   2 step    23900 |   2869 batches | lr 0.000158 | ms/batch 429.70 | loss  2.66 | avg loss  2.57 | ppl 13.08\n",
      "| epoch   2 step    24000 |   2969 batches | lr 0.000157 | ms/batch 429.71 | loss  3.51 | avg loss  2.63 | ppl 13.92\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.24000.pt\n",
      "eval samples: 0 loss: tensor(1.3869, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1668, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.4262, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9541, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2630, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7404, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1983, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3320, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5787, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.5233, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9386, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6028, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6988, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.8724, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.7948, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7652, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9785, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7731, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6607, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6580, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4112, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1183, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3719, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2329, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5625, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2048, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2183, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4640, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.8280, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9922, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.7217, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3234, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1812, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5637, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.5490, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7535, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6974, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.1125, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5210, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2041, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3950, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1971, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4483, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9014, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0179, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.0048, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3671, device='cuda:0')\n",
      "average loss 1.2638865545940623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  12 at step    24000 | time: 476.00s | valid loss  1.26 | valid ppl  3.54 | best ppl  3.49 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    24100 |   3069 batches | lr 0.000157 | ms/batch 5189.92 | loss  2.40 | avg loss  2.58 | ppl 13.24\n",
      "| epoch   2 step    24200 |   3169 batches | lr 0.000157 | ms/batch 429.58 | loss  2.20 | avg loss  2.60 | ppl 13.51\n",
      "| epoch   2 step    24300 |   3269 batches | lr 0.000157 | ms/batch 429.63 | loss  3.31 | avg loss  2.60 | ppl 13.50\n",
      "| epoch   2 step    24400 |   3369 batches | lr 0.000157 | ms/batch 429.71 | loss  2.16 | avg loss  2.62 | ppl 13.73\n",
      "| epoch   2 step    24500 |   3469 batches | lr 0.000156 | ms/batch 429.60 | loss  2.95 | avg loss  2.59 | ppl 13.39\n",
      "| epoch   2 step    24600 |   3569 batches | lr 0.000156 | ms/batch 429.65 | loss  3.02 | avg loss  2.53 | ppl 12.56\n",
      "| epoch   2 step    24700 |   3669 batches | lr 0.000156 | ms/batch 429.62 | loss  2.51 | avg loss  2.54 | ppl 12.68\n",
      "| epoch   2 step    24800 |   3769 batches | lr 0.000156 | ms/batch 429.74 | loss  2.45 | avg loss  2.57 | ppl 13.05\n",
      "| epoch   2 step    24900 |   3869 batches | lr 0.000156 | ms/batch 429.71 | loss  2.77 | avg loss  2.55 | ppl 12.84\n",
      "| epoch   2 step    25000 |   3969 batches | lr 0.000155 | ms/batch 429.50 | loss  2.39 | avg loss  2.58 | ppl 13.20\n",
      "| epoch   2 step    25100 |   4069 batches | lr 0.000155 | ms/batch 429.57 | loss  3.86 | avg loss  2.60 | ppl 13.48\n",
      "| epoch   2 step    25200 |   4169 batches | lr 0.000155 | ms/batch 429.48 | loss  2.36 | avg loss  2.57 | ppl 13.12\n",
      "| epoch   2 step    25300 |   4269 batches | lr 0.000155 | ms/batch 429.78 | loss  2.97 | avg loss  2.58 | ppl 13.23\n",
      "| epoch   2 step    25400 |   4369 batches | lr 0.000155 | ms/batch 429.60 | loss  2.68 | avg loss  2.63 | ppl 13.90\n",
      "| epoch   2 step    25500 |   4469 batches | lr 0.000154 | ms/batch 429.45 | loss  3.64 | avg loss  2.67 | ppl 14.50\n",
      "| epoch   2 step    25600 |   4569 batches | lr 0.000154 | ms/batch 429.54 | loss  2.88 | avg loss  2.56 | ppl 12.91\n",
      "| epoch   2 step    25700 |   4669 batches | lr 0.000154 | ms/batch 429.57 | loss  2.40 | avg loss  2.64 | ppl 13.96\n",
      "| epoch   2 step    25800 |   4769 batches | lr 0.000154 | ms/batch 429.68 | loss  2.88 | avg loss  2.55 | ppl 12.86\n",
      "| epoch   2 step    25900 |   4869 batches | lr 0.000154 | ms/batch 429.57 | loss  2.52 | avg loss  2.62 | ppl 13.72\n",
      "| epoch   2 step    26000 |   4969 batches | lr 0.000153 | ms/batch 429.50 | loss  2.36 | avg loss  2.57 | ppl 13.04\n",
      "eval samples: 0 loss: tensor(1.4000, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0210, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3904, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9752, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2955, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7068, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1250, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3413, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.7008, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4855, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9835, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6146, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6578, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7688, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6112, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7718, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9755, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7335, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6725, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5901, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3870, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0765, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3735, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2154, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4682, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2277, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.3082, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4197, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7427, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9774, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6890, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2839, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0090, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4473, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.4913, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7545, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7276, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.0370, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5148, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1518, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.4057, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1884, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4572, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8403, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0186, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9677, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3924, device='cuda:0')\n",
      "average loss 1.2452009906928527\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  13 at step    26000 | time: 476.04s | valid loss  1.25 | valid ppl  3.47 | best ppl  3.47 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    26100 |   5069 batches | lr 0.000153 | ms/batch 5190.14 | loss  2.03 | avg loss  2.61 | ppl 13.65\n",
      "| epoch   2 step    26200 |   5169 batches | lr 0.000153 | ms/batch 430.10 | loss  3.22 | avg loss  2.59 | ppl 13.36\n",
      "| epoch   2 step    26300 |   5269 batches | lr 0.000153 | ms/batch 428.93 | loss  2.57 | avg loss  2.59 | ppl 13.35\n",
      "| epoch   2 step    26400 |   5369 batches | lr 0.000153 | ms/batch 428.49 | loss  2.76 | avg loss  2.53 | ppl 12.57\n",
      "| epoch   2 step    26500 |   5469 batches | lr 0.000152 | ms/batch 428.77 | loss  2.68 | avg loss  2.56 | ppl 12.91\n",
      "| epoch   2 step    26600 |   5569 batches | lr 0.000152 | ms/batch 428.66 | loss  2.90 | avg loss  2.65 | ppl 14.21\n",
      "| epoch   2 step    26700 |   5669 batches | lr 0.000152 | ms/batch 428.43 | loss  2.66 | avg loss  2.59 | ppl 13.40\n",
      "| epoch   2 step    26800 |   5769 batches | lr 0.000152 | ms/batch 428.52 | loss  2.65 | avg loss  2.55 | ppl 12.76\n",
      "| epoch   2 step    26900 |   5869 batches | lr 0.000152 | ms/batch 428.32 | loss  2.37 | avg loss  2.55 | ppl 12.86\n",
      "| epoch   2 step    27000 |   5969 batches | lr 0.000152 | ms/batch 428.38 | loss  2.81 | avg loss  2.55 | ppl 12.84\n",
      "| epoch   2 step    27100 |   6069 batches | lr 0.000151 | ms/batch 428.28 | loss  2.35 | avg loss  2.57 | ppl 13.01\n",
      "| epoch   2 step    27200 |   6169 batches | lr 0.000151 | ms/batch 428.34 | loss  4.01 | avg loss  2.58 | ppl 13.18\n",
      "| epoch   2 step    27300 |   6269 batches | lr 0.000151 | ms/batch 428.31 | loss  2.51 | avg loss  2.56 | ppl 12.96\n",
      "| epoch   2 step    27400 |   6369 batches | lr 0.000151 | ms/batch 428.01 | loss  2.23 | avg loss  2.48 | ppl 11.96\n",
      "| epoch   2 step    27500 |   6469 batches | lr 0.000151 | ms/batch 428.43 | loss  2.54 | avg loss  2.57 | ppl 13.12\n",
      "| epoch   2 step    27600 |   6569 batches | lr 0.00015 | ms/batch 428.41 | loss  2.59 | avg loss  2.59 | ppl 13.38\n",
      "| epoch   2 step    27700 |   6669 batches | lr 0.00015 | ms/batch 428.40 | loss  2.33 | avg loss  2.60 | ppl 13.42\n",
      "| epoch   2 step    27800 |   6769 batches | lr 0.00015 | ms/batch 428.40 | loss  2.23 | avg loss  2.55 | ppl 12.80\n",
      "| epoch   2 step    27900 |   6869 batches | lr 0.00015 | ms/batch 428.39 | loss  2.38 | avg loss  2.55 | ppl 12.86\n",
      "| epoch   2 step    28000 |   6969 batches | lr 0.00015 | ms/batch 428.38 | loss  2.70 | avg loss  2.57 | ppl 13.02\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.28000.pt\n",
      "eval samples: 0 loss: tensor(1.3213, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1190, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3902, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9547, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2607, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7335, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1198, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3186, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5717, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.5005, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9695, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6254, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6789, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7634, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5541, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7200, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9441, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7759, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6879, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6904, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.4064, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0457, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3491, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2808, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5912, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1303, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.3357, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4035, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7115, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0036, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6624, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2617, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0869, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.3933, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.5214, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7465, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7798, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.0060, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5016, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1253, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3720, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1380, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4645, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8871, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9780, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9808, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3559, device='cuda:0')\n",
      "average loss 1.2521933531005904\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  14 at step    28000 | time: 474.71s | valid loss  1.25 | valid ppl  3.50 | best ppl  3.47 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    28100 |   7069 batches | lr 0.000149 | ms/batch 5175.27 | loss  2.81 | avg loss  2.56 | ppl 12.97\n",
      "| epoch   2 step    28200 |   7169 batches | lr 0.000149 | ms/batch 428.30 | loss  2.14 | avg loss  2.52 | ppl 12.47\n",
      "| epoch   2 step    28300 |   7269 batches | lr 0.000149 | ms/batch 428.34 | loss  3.38 | avg loss  2.49 | ppl 12.07\n",
      "| epoch   2 step    28400 |   7369 batches | lr 0.000149 | ms/batch 428.30 | loss  2.95 | avg loss  2.59 | ppl 13.29\n",
      "| epoch   2 step    28500 |   7469 batches | lr 0.000149 | ms/batch 428.28 | loss  2.25 | avg loss  2.53 | ppl 12.55\n",
      "| epoch   2 step    28600 |   7569 batches | lr 0.000148 | ms/batch 428.52 | loss  2.04 | avg loss  2.56 | ppl 12.90\n",
      "| epoch   2 step    28700 |   7669 batches | lr 0.000148 | ms/batch 428.68 | loss  2.21 | avg loss  2.56 | ppl 12.96\n",
      "| epoch   2 step    28800 |   7769 batches | lr 0.000148 | ms/batch 428.62 | loss  2.27 | avg loss  2.56 | ppl 12.97\n",
      "| epoch   2 step    28900 |   7869 batches | lr 0.000148 | ms/batch 428.53 | loss  2.01 | avg loss  2.55 | ppl 12.81\n",
      "| epoch   2 step    29000 |   7969 batches | lr 0.000148 | ms/batch 428.11 | loss  2.62 | avg loss  2.56 | ppl 12.90\n",
      "| epoch   2 step    29100 |   8069 batches | lr 0.000147 | ms/batch 428.34 | loss  2.94 | avg loss  2.61 | ppl 13.60\n",
      "| epoch   2 step    29200 |   8169 batches | lr 0.000147 | ms/batch 428.32 | loss  2.56 | avg loss  2.61 | ppl 13.59\n",
      "| epoch   2 step    29300 |   8269 batches | lr 0.000147 | ms/batch 428.35 | loss  3.09 | avg loss  2.57 | ppl 13.11\n",
      "| epoch   2 step    29400 |   8369 batches | lr 0.000147 | ms/batch 428.15 | loss  2.79 | avg loss  2.56 | ppl 12.94\n",
      "| epoch   2 step    29500 |   8469 batches | lr 0.000147 | ms/batch 428.26 | loss  2.10 | avg loss  2.55 | ppl 12.82\n",
      "| epoch   2 step    29600 |   8569 batches | lr 0.000146 | ms/batch 428.33 | loss  2.73 | avg loss  2.59 | ppl 13.30\n",
      "| epoch   2 step    29700 |   8669 batches | lr 0.000146 | ms/batch 428.28 | loss  2.32 | avg loss  2.53 | ppl 12.52\n",
      "| epoch   2 step    29800 |   8769 batches | lr 0.000146 | ms/batch 428.34 | loss  2.28 | avg loss  2.55 | ppl 12.76\n",
      "| epoch   2 step    29900 |   8869 batches | lr 0.000146 | ms/batch 428.27 | loss  2.78 | avg loss  2.54 | ppl 12.72\n",
      "| epoch   2 step    30000 |   8969 batches | lr 0.000146 | ms/batch 428.22 | loss  2.48 | avg loss  2.57 | ppl 13.13\n",
      "eval samples: 0 loss: tensor(1.3753, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1287, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3574, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9265, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1988, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6861, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0926, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2883, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5983, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4510, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8957, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6073, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6855, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7540, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.7079, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.6854, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9518, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7882, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6039, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5869, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3506, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0617, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3266, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1748, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4375, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1965, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2609, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.4228, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7562, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9679, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6539, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2853, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0931, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.3863, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.4546, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7288, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7031, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9807, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5160, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2506, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.4256, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1106, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4562, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9431, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9115, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9396, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3588, device='cuda:0')\n",
      "average loss 1.2299706241792094\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  15 at step    30000 | time: 474.42s | valid loss  1.23 | valid ppl  3.42 | best ppl  3.42 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    30100 |   9069 batches | lr 0.000146 | ms/batch 5172.51 | loss  2.41 | avg loss  2.57 | ppl 13.07\n",
      "| epoch   2 step    30200 |   9169 batches | lr 0.000145 | ms/batch 428.27 | loss  2.93 | avg loss  2.58 | ppl 13.14\n",
      "| epoch   2 step    30300 |   9269 batches | lr 0.000145 | ms/batch 427.99 | loss  2.82 | avg loss  2.55 | ppl 12.77\n",
      "| epoch   2 step    30400 |   9369 batches | lr 0.000145 | ms/batch 428.05 | loss  2.42 | avg loss  2.65 | ppl 14.11\n",
      "| epoch   2 step    30500 |   9469 batches | lr 0.000145 | ms/batch 427.99 | loss  2.52 | avg loss  2.58 | ppl 13.21\n",
      "| epoch   2 step    30600 |   9569 batches | lr 0.000145 | ms/batch 428.36 | loss  2.34 | avg loss  2.64 | ppl 13.98\n",
      "| epoch   2 step    30700 |   9669 batches | lr 0.000144 | ms/batch 428.14 | loss  2.22 | avg loss  2.54 | ppl 12.69\n",
      "| epoch   2 step    30800 |   9769 batches | lr 0.000144 | ms/batch 428.31 | loss  2.36 | avg loss  2.63 | ppl 13.82\n",
      "| epoch   2 step    30900 |   9869 batches | lr 0.000144 | ms/batch 428.20 | loss  2.53 | avg loss  2.57 | ppl 13.06\n",
      "| epoch   2 step    31000 |   9969 batches | lr 0.000144 | ms/batch 428.35 | loss  2.27 | avg loss  2.58 | ppl 13.21\n",
      "| epoch   2 step    31100 |  10069 batches | lr 0.000144 | ms/batch 428.29 | loss  3.11 | avg loss  2.56 | ppl 12.90\n",
      "| epoch   2 step    31200 |  10169 batches | lr 0.000143 | ms/batch 428.17 | loss  2.66 | avg loss  2.55 | ppl 12.79\n",
      "| epoch   2 step    31300 |  10269 batches | lr 0.000143 | ms/batch 428.34 | loss  2.07 | avg loss  2.58 | ppl 13.24\n",
      "| epoch   2 step    31400 |  10369 batches | lr 0.000143 | ms/batch 428.41 | loss  2.71 | avg loss  2.60 | ppl 13.52\n",
      "| epoch   2 step    31500 |  10469 batches | lr 0.000143 | ms/batch 428.05 | loss  2.30 | avg loss  2.49 | ppl 12.07\n",
      "| epoch   2 step    31600 |  10569 batches | lr 0.000143 | ms/batch 428.28 | loss  3.13 | avg loss  2.53 | ppl 12.55\n",
      "| epoch   2 step    31700 |  10669 batches | lr 0.000142 | ms/batch 428.81 | loss  2.57 | avg loss  2.55 | ppl 12.87\n",
      "| epoch   2 step    31800 |  10769 batches | lr 0.000142 | ms/batch 428.55 | loss  2.71 | avg loss  2.59 | ppl 13.30\n",
      "| epoch   2 step    31900 |  10869 batches | lr 0.000142 | ms/batch 428.47 | loss  2.30 | avg loss  2.55 | ppl 12.82\n",
      "| epoch   2 step    32000 |  10969 batches | lr 0.000142 | ms/batch 428.33 | loss  2.67 | avg loss  2.56 | ppl 13.00\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.32000.pt\n",
      "eval samples: 0 loss: tensor(1.4104, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1369, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3163, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9143, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2564, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6882, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0695, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3317, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.6488, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4728, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8994, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.6372, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6950, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.8035, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6030, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7194, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9951, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7112, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6944, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.6194, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3175, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0581, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3907, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1813, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5087, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2010, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.3447, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3826, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7072, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0694, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6581, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.3031, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1081, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.3714, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.4119, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6837, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7173, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.0447, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.5172, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1940, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.4456, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1510, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4758, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9519, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9803, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9285, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3264, device='cuda:0')\n",
      "average loss 1.2391761836838233\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  16 at step    32000 | time: 474.45s | valid loss  1.24 | valid ppl  3.45 | best ppl  3.42 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    32100 |  11069 batches | lr 0.000142 | ms/batch 5172.96 | loss  2.55 | avg loss  2.59 | ppl 13.29\n",
      "| epoch   2 step    32200 |  11169 batches | lr 0.000141 | ms/batch 428.22 | loss  2.58 | avg loss  2.53 | ppl 12.58\n",
      "| epoch   2 step    32300 |  11269 batches | lr 0.000141 | ms/batch 428.29 | loss  2.28 | avg loss  2.54 | ppl 12.63\n",
      "| epoch   2 step    32400 |  11369 batches | lr 0.000141 | ms/batch 428.19 | loss  2.24 | avg loss  2.54 | ppl 12.63\n",
      "| epoch   2 step    32500 |  11469 batches | lr 0.000141 | ms/batch 428.35 | loss  2.45 | avg loss  2.53 | ppl 12.50\n",
      "| epoch   2 step    32600 |  11569 batches | lr 0.000141 | ms/batch 428.38 | loss  2.92 | avg loss  2.61 | ppl 13.64\n",
      "| epoch   2 step    32700 |  11669 batches | lr 0.00014 | ms/batch 428.36 | loss  2.37 | avg loss  2.53 | ppl 12.53\n",
      "| epoch   2 step    32800 |  11769 batches | lr 0.00014 | ms/batch 428.47 | loss  2.63 | avg loss  2.58 | ppl 13.18\n",
      "| epoch   2 step    32900 |  11869 batches | lr 0.00014 | ms/batch 428.89 | loss  2.45 | avg loss  2.62 | ppl 13.71\n",
      "| epoch   2 step    33000 |  11969 batches | lr 0.00014 | ms/batch 428.58 | loss  2.75 | avg loss  2.56 | ppl 13.00\n",
      "| epoch   2 step    33100 |  12069 batches | lr 0.00014 | ms/batch 428.55 | loss  2.37 | avg loss  2.55 | ppl 12.80\n",
      "| epoch   2 step    33200 |  12169 batches | lr 0.00014 | ms/batch 428.61 | loss  2.52 | avg loss  2.48 | ppl 12.00\n",
      "| epoch   2 step    33300 |  12269 batches | lr 0.000139 | ms/batch 428.92 | loss  2.37 | avg loss  2.54 | ppl 12.65\n",
      "| epoch   2 step    33400 |  12369 batches | lr 0.000139 | ms/batch 428.86 | loss  2.88 | avg loss  2.60 | ppl 13.52\n",
      "| epoch   2 step    33500 |  12469 batches | lr 0.000139 | ms/batch 428.50 | loss  2.60 | avg loss  2.60 | ppl 13.53\n",
      "| epoch   2 step    33600 |  12569 batches | lr 0.000139 | ms/batch 428.35 | loss  2.75 | avg loss  2.59 | ppl 13.26\n",
      "| epoch   2 step    33700 |  12669 batches | lr 0.000139 | ms/batch 428.43 | loss  2.93 | avg loss  2.56 | ppl 12.92\n",
      "| epoch   2 step    33800 |  12769 batches | lr 0.000138 | ms/batch 428.50 | loss  2.11 | avg loss  2.55 | ppl 12.80\n",
      "| epoch   2 step    33900 |  12869 batches | lr 0.000138 | ms/batch 428.98 | loss  2.95 | avg loss  2.56 | ppl 12.94\n",
      "| epoch   2 step    34000 |  12969 batches | lr 0.000138 | ms/batch 428.73 | loss  2.00 | avg loss  2.64 | ppl 14.03\n",
      "eval samples: 0 loss: tensor(1.4506, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0821, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3203, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9226, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1862, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7334, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1109, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2819, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.6222, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4162, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9350, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5894, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6550, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7516, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6307, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7367, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9979, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7899, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6448, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5420, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3199, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1065, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3370, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2257, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5080, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2106, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2225, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3993, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7605, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9771, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6802, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2616, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1316, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4774, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.4177, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6801, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7281, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.0266, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.4534, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1934, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3557, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1471, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3666, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8735, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9544, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9198, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2587, device='cuda:0')\n",
      "average loss 1.2307248266975153\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  17 at step    34000 | time: 474.81s | valid loss  1.23 | valid ppl  3.42 | best ppl  3.42 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    34100 |  13069 batches | lr 0.000138 | ms/batch 5176.39 | loss  2.15 | avg loss  2.55 | ppl 12.84\n",
      "| epoch   2 step    34200 |  13169 batches | lr 0.000138 | ms/batch 428.34 | loss  2.85 | avg loss  2.51 | ppl 12.26\n",
      "| epoch   2 step    34300 |  13269 batches | lr 0.000137 | ms/batch 428.32 | loss  2.99 | avg loss  2.58 | ppl 13.19\n",
      "| epoch   2 step    34400 |  13369 batches | lr 0.000137 | ms/batch 428.36 | loss  2.55 | avg loss  2.54 | ppl 12.72\n",
      "| epoch   2 step    34500 |  13469 batches | lr 0.000137 | ms/batch 428.41 | loss  2.82 | avg loss  2.55 | ppl 12.84\n",
      "| epoch   2 step    34600 |  13569 batches | lr 0.000137 | ms/batch 428.35 | loss  3.09 | avg loss  2.56 | ppl 12.87\n",
      "| epoch   2 step    34700 |  13669 batches | lr 0.000137 | ms/batch 428.45 | loss  2.67 | avg loss  2.56 | ppl 12.99\n",
      "| epoch   2 step    34800 |  13769 batches | lr 0.000136 | ms/batch 428.41 | loss  3.47 | avg loss  2.50 | ppl 12.17\n",
      "| epoch   2 step    34900 |  13869 batches | lr 0.000136 | ms/batch 428.40 | loss  2.26 | avg loss  2.55 | ppl 12.85\n",
      "| epoch   2 step    35000 |  13969 batches | lr 0.000136 | ms/batch 428.39 | loss  2.21 | avg loss  2.56 | ppl 12.92\n",
      "| epoch   2 step    35100 |  14069 batches | lr 0.000136 | ms/batch 428.32 | loss  2.97 | avg loss  2.56 | ppl 13.00\n",
      "| epoch   2 step    35200 |  14169 batches | lr 0.000136 | ms/batch 428.48 | loss  2.46 | avg loss  2.60 | ppl 13.49\n",
      "| epoch   2 step    35300 |  14269 batches | lr 0.000135 | ms/batch 428.38 | loss  2.41 | avg loss  2.55 | ppl 12.85\n",
      "| epoch   2 step    35400 |  14369 batches | lr 0.000135 | ms/batch 428.34 | loss  3.32 | avg loss  2.57 | ppl 13.07\n",
      "| epoch   2 step    35500 |  14469 batches | lr 0.000135 | ms/batch 428.38 | loss  2.70 | avg loss  2.59 | ppl 13.28\n",
      "| epoch   2 step    35600 |  14569 batches | lr 0.000135 | ms/batch 428.38 | loss  3.06 | avg loss  2.60 | ppl 13.47\n",
      "| epoch   2 step    35700 |  14669 batches | lr 0.000135 | ms/batch 428.49 | loss  2.24 | avg loss  2.49 | ppl 12.09\n",
      "| epoch   2 step    35800 |  14769 batches | lr 0.000134 | ms/batch 428.42 | loss  2.09 | avg loss  2.54 | ppl 12.73\n",
      "| epoch   2 step    35900 |  14869 batches | lr 0.000134 | ms/batch 428.41 | loss  2.15 | avg loss  2.66 | ppl 14.34\n",
      "| epoch   2 step    36000 |  14969 batches | lr 0.000134 | ms/batch 428.27 | loss  3.14 | avg loss  2.50 | ppl 12.21\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.36000.pt\n",
      "eval samples: 0 loss: tensor(1.4523, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1406, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3321, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9426, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2251, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6742, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0798, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3432, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.6573, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4672, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9323, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5367, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6421, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7706, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5237, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7488, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9786, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7845, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.5782, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5973, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3398, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0640, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3448, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2804, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4508, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2000, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2565, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3937, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6583, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9428, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6389, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2533, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1631, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.5078, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.4487, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.7149, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.7746, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9679, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.4941, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1728, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3593, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1965, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3261, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9241, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9864, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(1.0305, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2913, device='cuda:0')\n",
      "average loss 1.223254346843707\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  18 at step    36000 | time: 474.87s | valid loss  1.22 | valid ppl  3.40 | best ppl  3.40 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    36100 |  15069 batches | lr 0.000134 | ms/batch 5177.05 | loss  2.69 | avg loss  2.50 | ppl 12.14\n",
      "| epoch   2 step    36200 |  15169 batches | lr 0.000134 | ms/batch 428.35 | loss  2.68 | avg loss  2.59 | ppl 13.29\n",
      "| epoch   2 step    36300 |  15269 batches | lr 0.000133 | ms/batch 428.49 | loss  2.05 | avg loss  2.53 | ppl 12.59\n",
      "| epoch   2 step    36400 |  15369 batches | lr 0.000133 | ms/batch 428.65 | loss  2.29 | avg loss  2.57 | ppl 13.02\n",
      "| epoch   2 step    36500 |  15469 batches | lr 0.000133 | ms/batch 428.45 | loss  2.15 | avg loss  2.55 | ppl 12.76\n",
      "| epoch   2 step    36600 |  15569 batches | lr 0.000133 | ms/batch 428.67 | loss  1.98 | avg loss  2.55 | ppl 12.83\n",
      "| epoch   2 step    36700 |  15669 batches | lr 0.000133 | ms/batch 429.19 | loss  2.36 | avg loss  2.51 | ppl 12.28\n",
      "| epoch   2 step    36800 |  15769 batches | lr 0.000133 | ms/batch 428.87 | loss  2.89 | avg loss  2.52 | ppl 12.42\n",
      "| epoch   2 step    36900 |  15869 batches | lr 0.000132 | ms/batch 428.63 | loss  2.84 | avg loss  2.60 | ppl 13.42\n",
      "| epoch   2 step    37000 |  15969 batches | lr 0.000132 | ms/batch 429.47 | loss  2.49 | avg loss  2.60 | ppl 13.50\n",
      "| epoch   2 step    37100 |  16069 batches | lr 0.000132 | ms/batch 428.63 | loss  2.41 | avg loss  2.56 | ppl 12.97\n",
      "| epoch   2 step    37200 |  16169 batches | lr 0.000132 | ms/batch 428.49 | loss  2.50 | avg loss  2.54 | ppl 12.62\n",
      "| epoch   2 step    37300 |  16269 batches | lr 0.000132 | ms/batch 429.37 | loss  2.73 | avg loss  2.55 | ppl 12.82\n",
      "| epoch   2 step    37400 |  16369 batches | lr 0.000131 | ms/batch 428.93 | loss  2.51 | avg loss  2.55 | ppl 12.75\n",
      "| epoch   2 step    37500 |  16469 batches | lr 0.000131 | ms/batch 428.62 | loss  2.74 | avg loss  2.54 | ppl 12.71\n",
      "| epoch   2 step    37600 |  16569 batches | lr 0.000131 | ms/batch 428.48 | loss  2.22 | avg loss  2.55 | ppl 12.79\n",
      "| epoch   2 step    37700 |  16669 batches | lr 0.000131 | ms/batch 428.59 | loss  2.20 | avg loss  2.60 | ppl 13.41\n",
      "| epoch   2 step    37800 |  16769 batches | lr 0.000131 | ms/batch 429.08 | loss  2.50 | avg loss  2.61 | ppl 13.65\n",
      "| epoch   2 step    37900 |  16869 batches | lr 0.00013 | ms/batch 428.68 | loss  2.87 | avg loss  2.56 | ppl 12.90\n",
      "| epoch   2 step    38000 |  16969 batches | lr 0.00013 | ms/batch 428.61 | loss  2.59 | avg loss  2.54 | ppl 12.70\n",
      "eval samples: 0 loss: tensor(1.3969, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0430, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3067, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8756, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1879, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6977, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0664, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2458, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5956, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4742, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9198, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5724, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6834, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7429, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6036, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7159, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9669, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7084, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6073, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5679, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3217, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1130, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3634, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1113, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5265, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1972, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.3029, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3731, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6761, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0151, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6530, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2603, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1030, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4939, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3565, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6631, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6534, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9926, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.4172, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2130, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3709, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1136, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4408, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9222, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9337, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9632, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2764, device='cuda:0')\n",
      "average loss 1.2218417100710413\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  19 at step    38000 | time: 475.13s | valid loss  1.22 | valid ppl  3.39 | best ppl  3.39 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    38100 |  17069 batches | lr 0.00013 | ms/batch 5179.86 | loss  2.85 | avg loss  2.60 | ppl 13.51\n",
      "| epoch   2 step    38200 |  17169 batches | lr 0.00013 | ms/batch 428.50 | loss  2.80 | avg loss  2.52 | ppl 12.45\n",
      "| epoch   2 step    38300 |  17269 batches | lr 0.00013 | ms/batch 428.44 | loss  2.37 | avg loss  2.61 | ppl 13.54\n",
      "| epoch   2 step    38400 |  17369 batches | lr 0.000129 | ms/batch 428.65 | loss  2.71 | avg loss  2.50 | ppl 12.15\n",
      "| epoch   2 step    38500 |  17469 batches | lr 0.000129 | ms/batch 428.30 | loss  2.24 | avg loss  2.56 | ppl 12.91\n",
      "| epoch   2 step    38600 |  17569 batches | lr 0.000129 | ms/batch 428.32 | loss  2.47 | avg loss  2.54 | ppl 12.67\n",
      "| epoch   2 step    38700 |  17669 batches | lr 0.000129 | ms/batch 428.15 | loss  2.21 | avg loss  2.49 | ppl 12.05\n",
      "| epoch   2 step    38800 |  17769 batches | lr 0.000129 | ms/batch 428.61 | loss  3.08 | avg loss  2.63 | ppl 13.84\n",
      "| epoch   2 step    38900 |  17869 batches | lr 0.000128 | ms/batch 428.54 | loss  2.58 | avg loss  2.52 | ppl 12.48\n",
      "| epoch   2 step    39000 |  17969 batches | lr 0.000128 | ms/batch 428.36 | loss  1.96 | avg loss  2.49 | ppl 12.10\n",
      "| epoch   2 step    39100 |  18069 batches | lr 0.000128 | ms/batch 428.56 | loss  2.56 | avg loss  2.55 | ppl 12.82\n",
      "| epoch   2 step    39200 |  18169 batches | lr 0.000128 | ms/batch 428.60 | loss  2.74 | avg loss  2.56 | ppl 12.90\n",
      "| epoch   2 step    39300 |  18269 batches | lr 0.000128 | ms/batch 428.46 | loss  2.23 | avg loss  2.52 | ppl 12.40\n",
      "| epoch   2 step    39400 |  18369 batches | lr 0.000127 | ms/batch 428.40 | loss  3.07 | avg loss  2.48 | ppl 11.93\n",
      "| epoch   2 step    39500 |  18469 batches | lr 0.000127 | ms/batch 428.59 | loss  3.53 | avg loss  2.56 | ppl 12.92\n",
      "| epoch   2 step    39600 |  18569 batches | lr 0.000127 | ms/batch 428.41 | loss  2.55 | avg loss  2.49 | ppl 12.08\n",
      "| epoch   2 step    39700 |  18669 batches | lr 0.000127 | ms/batch 428.50 | loss  3.32 | avg loss  2.51 | ppl 12.27\n",
      "| epoch   2 step    39800 |  18769 batches | lr 0.000127 | ms/batch 428.44 | loss  2.92 | avg loss  2.51 | ppl 12.32\n",
      "| epoch   2 step    39900 |  18869 batches | lr 0.000127 | ms/batch 428.61 | loss  2.43 | avg loss  2.64 | ppl 14.01\n",
      "| epoch   2 step    40000 |  18969 batches | lr 0.000126 | ms/batch 428.57 | loss  2.28 | avg loss  2.59 | ppl 13.31\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.40000.pt\n",
      "eval samples: 0 loss: tensor(1.4989, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0394, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3325, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9525, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1731, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6894, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.1227, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2344, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5729, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.5235, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9530, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5827, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6258, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7156, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6264, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7088, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(1.0212, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7628, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6237, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5887, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3402, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1324, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3493, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1628, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.5567, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1935, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2836, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3380, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6996, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9503, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6657, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2774, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1166, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4799, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.4451, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6887, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6280, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9345, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.4834, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2055, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3842, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1144, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4020, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9658, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0084, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9387, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3490, device='cuda:0')\n",
      "average loss 1.2220246621331021\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  20 at step    40000 | time: 474.93s | valid loss  1.22 | valid ppl  3.39 | best ppl  3.39 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   2 step    40100 |  19069 batches | lr 0.000126 | ms/batch 5178.00 | loss  2.15 | avg loss  2.58 | ppl 13.19\n",
      "| epoch   2 step    40200 |  19169 batches | lr 0.000126 | ms/batch 428.70 | loss  2.07 | avg loss  2.55 | ppl 12.83\n",
      "| epoch   2 step    40300 |  19269 batches | lr 0.000126 | ms/batch 428.71 | loss  3.04 | avg loss  2.58 | ppl 13.16\n",
      "| epoch   2 step    40400 |  19369 batches | lr 0.000126 | ms/batch 428.53 | loss  2.73 | avg loss  2.58 | ppl 13.18\n",
      "| epoch   2 step    40500 |  19469 batches | lr 0.000125 | ms/batch 428.52 | loss  3.07 | avg loss  2.51 | ppl 12.35\n",
      "| epoch   2 step    40600 |  19569 batches | lr 0.000125 | ms/batch 428.65 | loss  2.73 | avg loss  2.58 | ppl 13.23\n",
      "| epoch   2 step    40700 |  19669 batches | lr 0.000125 | ms/batch 428.40 | loss  2.17 | avg loss  2.64 | ppl 13.95\n",
      "| epoch   2 step    40800 |  19769 batches | lr 0.000125 | ms/batch 428.39 | loss  2.72 | avg loss  2.49 | ppl 12.02\n",
      "| epoch   2 step    40900 |  19869 batches | lr 0.000125 | ms/batch 428.68 | loss  2.59 | avg loss  2.51 | ppl 12.34\n",
      "| epoch   2 step    41000 |  19969 batches | lr 0.000124 | ms/batch 428.71 | loss  2.60 | avg loss  2.62 | ppl 13.76\n",
      "| epoch   2 step    41100 |  20069 batches | lr 0.000124 | ms/batch 428.38 | loss  2.60 | avg loss  2.51 | ppl 12.31\n",
      "| epoch   2 step    41200 |  20169 batches | lr 0.000124 | ms/batch 428.32 | loss  2.15 | avg loss  2.53 | ppl 12.52\n",
      "| epoch   2 step    41300 |  20269 batches | lr 0.000124 | ms/batch 428.58 | loss  2.81 | avg loss  2.58 | ppl 13.17\n",
      "| epoch   2 step    41400 |  20369 batches | lr 0.000124 | ms/batch 428.56 | loss  2.51 | avg loss  2.59 | ppl 13.32\n",
      "| epoch   2 step    41500 |  20469 batches | lr 0.000123 | ms/batch 428.26 | loss  2.56 | avg loss  2.58 | ppl 13.26\n",
      "| epoch   2 step    41600 |  20569 batches | lr 0.000123 | ms/batch 428.48 | loss  2.38 | avg loss  2.52 | ppl 12.41\n",
      "| epoch   2 step    41700 |  20669 batches | lr 0.000123 | ms/batch 428.43 | loss  2.72 | avg loss  2.52 | ppl 12.42\n",
      "| epoch   2 step    41800 |  20769 batches | lr 0.000123 | ms/batch 428.17 | loss  2.32 | avg loss  2.51 | ppl 12.34\n",
      "| epoch   2 step    41900 |  20869 batches | lr 0.000123 | ms/batch 428.55 | loss  2.53 | avg loss  2.50 | ppl 12.24\n",
      "| epoch   2 step    42000 |  20969 batches | lr 0.000122 | ms/batch 428.55 | loss  2.51 | avg loss  2.46 | ppl 11.72\n",
      "eval samples: 0 loss: tensor(1.4069, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0801, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3203, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9551, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2230, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7078, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(0.9950, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3435, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5564, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4184, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9125, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5577, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6586, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7905, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.7254, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7432, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9915, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7109, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6263, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5973, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3349, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0821, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.2965, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2546, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4348, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2106, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2628, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3652, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6807, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0408, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6729, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.1915, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1719, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4471, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3496, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6711, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6504, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9793, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.4369, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2061, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3502, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0905, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3758, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8896, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9588, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9241, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3088, device='cuda:0')\n",
      "average loss 1.2213669971958414\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  21 at step    42000 | time: 474.99s | valid loss  1.22 | valid ppl  3.39 | best ppl  3.39 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.42062.pt\n",
      "start to train the model................ 3\n",
      "| epoch   3 step    42100 |     38 batches | lr 0.000122 | ms/batch 163.06 | loss  3.25 | avg loss  2.54 | ppl 12.71\n",
      "| epoch   3 step    42200 |    138 batches | lr 0.000122 | ms/batch 428.54 | loss  2.34 | avg loss  2.53 | ppl 12.53\n",
      "| epoch   3 step    42300 |    238 batches | lr 0.000122 | ms/batch 428.61 | loss  3.03 | avg loss  2.50 | ppl 12.23\n",
      "| epoch   3 step    42400 |    338 batches | lr 0.000122 | ms/batch 428.63 | loss  2.36 | avg loss  2.59 | ppl 13.28\n",
      "| epoch   3 step    42500 |    438 batches | lr 0.000121 | ms/batch 428.54 | loss  1.85 | avg loss  2.59 | ppl 13.38\n",
      "| epoch   3 step    42600 |    538 batches | lr 0.000121 | ms/batch 428.52 | loss  2.17 | avg loss  2.54 | ppl 12.73\n",
      "| epoch   3 step    42700 |    638 batches | lr 0.000121 | ms/batch 428.55 | loss  2.81 | avg loss  2.58 | ppl 13.17\n",
      "| epoch   3 step    42800 |    738 batches | lr 0.000121 | ms/batch 428.48 | loss  2.13 | avg loss  2.44 | ppl 11.45\n",
      "| epoch   3 step    42900 |    838 batches | lr 0.000121 | ms/batch 428.39 | loss  2.32 | avg loss  2.55 | ppl 12.75\n",
      "| epoch   3 step    43000 |    938 batches | lr 0.000121 | ms/batch 428.45 | loss  2.28 | avg loss  2.54 | ppl 12.63\n",
      "| epoch   3 step    43100 |   1038 batches | lr 0.00012 | ms/batch 428.39 | loss  2.18 | avg loss  2.56 | ppl 12.87\n",
      "| epoch   3 step    43200 |   1138 batches | lr 0.00012 | ms/batch 428.36 | loss  2.50 | avg loss  2.51 | ppl 12.30\n",
      "| epoch   3 step    43300 |   1238 batches | lr 0.00012 | ms/batch 428.36 | loss  2.49 | avg loss  2.52 | ppl 12.41\n",
      "| epoch   3 step    43400 |   1338 batches | lr 0.00012 | ms/batch 428.25 | loss  2.33 | avg loss  2.56 | ppl 12.94\n",
      "| epoch   3 step    43500 |   1438 batches | lr 0.00012 | ms/batch 428.16 | loss  2.89 | avg loss  2.50 | ppl 12.21\n",
      "| epoch   3 step    43600 |   1538 batches | lr 0.000119 | ms/batch 428.60 | loss  2.27 | avg loss  2.52 | ppl 12.43\n",
      "| epoch   3 step    43700 |   1638 batches | lr 0.000119 | ms/batch 428.43 | loss  3.21 | avg loss  2.56 | ppl 12.91\n",
      "| epoch   3 step    43800 |   1738 batches | lr 0.000119 | ms/batch 428.48 | loss  2.92 | avg loss  2.56 | ppl 12.93\n",
      "| epoch   3 step    43900 |   1838 batches | lr 0.000119 | ms/batch 428.55 | loss  2.75 | avg loss  2.54 | ppl 12.69\n",
      "| epoch   3 step    44000 |   1938 batches | lr 0.000119 | ms/batch 428.53 | loss  2.56 | avg loss  2.59 | ppl 13.31\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.44000.pt\n",
      "eval samples: 0 loss: tensor(1.3776, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.1137, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3142, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8352, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1601, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6965, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0648, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2930, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5695, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4494, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9408, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5963, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6493, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7632, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5971, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7556, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.8846, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7019, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6295, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5510, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3341, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1183, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3192, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2098, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4299, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1367, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2562, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3493, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7231, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0560, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6976, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2734, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0792, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4541, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3670, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6266, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6149, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9479, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.4635, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1925, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3519, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0778, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3769, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8670, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9912, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9385, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3235, device='cuda:0')\n",
      "average loss 1.2110470541025677\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  22 at step    44000 | time: 474.91s | valid loss  1.21 | valid ppl  3.36 | best ppl  3.36 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    44100 |   2038 batches | lr 0.000118 | ms/batch 5177.71 | loss  2.10 | avg loss  2.48 | ppl 11.96\n",
      "| epoch   3 step    44200 |   2138 batches | lr 0.000118 | ms/batch 428.48 | loss  3.22 | avg loss  2.61 | ppl 13.66\n",
      "| epoch   3 step    44300 |   2238 batches | lr 0.000118 | ms/batch 428.49 | loss  2.43 | avg loss  2.54 | ppl 12.72\n",
      "| epoch   3 step    44400 |   2338 batches | lr 0.000118 | ms/batch 428.41 | loss  3.11 | avg loss  2.54 | ppl 12.69\n",
      "| epoch   3 step    44500 |   2438 batches | lr 0.000118 | ms/batch 428.43 | loss  2.80 | avg loss  2.51 | ppl 12.32\n",
      "| epoch   3 step    44600 |   2538 batches | lr 0.000117 | ms/batch 428.52 | loss  2.33 | avg loss  2.56 | ppl 12.97\n",
      "| epoch   3 step    44700 |   2638 batches | lr 0.000117 | ms/batch 428.32 | loss  2.15 | avg loss  2.55 | ppl 12.81\n",
      "| epoch   3 step    44800 |   2738 batches | lr 0.000117 | ms/batch 428.49 | loss  2.90 | avg loss  2.53 | ppl 12.61\n",
      "| epoch   3 step    44900 |   2838 batches | lr 0.000117 | ms/batch 428.58 | loss  2.16 | avg loss  2.52 | ppl 12.49\n",
      "| epoch   3 step    45000 |   2938 batches | lr 0.000117 | ms/batch 428.49 | loss  2.37 | avg loss  2.57 | ppl 13.02\n",
      "| epoch   3 step    45100 |   3038 batches | lr 0.000116 | ms/batch 428.29 | loss  2.51 | avg loss  2.54 | ppl 12.74\n",
      "| epoch   3 step    45200 |   3138 batches | lr 0.000116 | ms/batch 428.57 | loss  2.26 | avg loss  2.60 | ppl 13.49\n",
      "| epoch   3 step    45300 |   3238 batches | lr 0.000116 | ms/batch 428.53 | loss  2.52 | avg loss  2.56 | ppl 12.87\n",
      "| epoch   3 step    45400 |   3338 batches | lr 0.000116 | ms/batch 428.57 | loss  2.89 | avg loss  2.47 | ppl 11.84\n",
      "| epoch   3 step    45500 |   3438 batches | lr 0.000116 | ms/batch 428.60 | loss  2.73 | avg loss  2.48 | ppl 11.91\n",
      "| epoch   3 step    45600 |   3538 batches | lr 0.000115 | ms/batch 428.44 | loss  2.42 | avg loss  2.55 | ppl 12.85\n",
      "| epoch   3 step    45700 |   3638 batches | lr 0.000115 | ms/batch 428.49 | loss  4.05 | avg loss  2.57 | ppl 13.10\n",
      "| epoch   3 step    45800 |   3738 batches | lr 0.000115 | ms/batch 428.41 | loss  2.87 | avg loss  2.56 | ppl 12.88\n",
      "| epoch   3 step    45900 |   3838 batches | lr 0.000115 | ms/batch 428.17 | loss  2.13 | avg loss  2.49 | ppl 12.10\n",
      "| epoch   3 step    46000 |   3938 batches | lr 0.000115 | ms/batch 428.39 | loss  2.56 | avg loss  2.48 | ppl 11.99\n",
      "eval samples: 0 loss: tensor(1.4462, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0327, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.2769, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8759, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1677, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6909, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0788, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2916, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5438, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4565, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9714, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5356, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6299, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7305, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6843, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7092, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9444, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7498, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6469, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5606, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3012, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0959, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3509, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1002, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4790, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.2297, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2461, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3934, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6877, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9906, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6395, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2466, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1124, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4336, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3380, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6191, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6398, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9242, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.4441, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2341, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3668, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1513, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3935, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9288, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9834, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9087, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3066, device='cuda:0')\n",
      "average loss 1.2074915223997342\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  23 at step    46000 | time: 474.83s | valid loss  1.21 | valid ppl  3.35 | best ppl  3.35 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    46100 |   4038 batches | lr 0.000114 | ms/batch 5176.89 | loss  2.76 | avg loss  2.55 | ppl 12.83\n",
      "| epoch   3 step    46200 |   4138 batches | lr 0.000114 | ms/batch 428.43 | loss  2.76 | avg loss  2.57 | ppl 13.11\n",
      "| epoch   3 step    46300 |   4238 batches | lr 0.000114 | ms/batch 428.63 | loss  2.61 | avg loss  2.50 | ppl 12.14\n",
      "| epoch   3 step    46400 |   4338 batches | lr 0.000114 | ms/batch 428.66 | loss  2.43 | avg loss  2.51 | ppl 12.25\n",
      "| epoch   3 step    46500 |   4438 batches | lr 0.000114 | ms/batch 428.54 | loss  1.98 | avg loss  2.51 | ppl 12.36\n",
      "| epoch   3 step    46600 |   4538 batches | lr 0.000114 | ms/batch 428.57 | loss  2.33 | avg loss  2.51 | ppl 12.31\n",
      "| epoch   3 step    46700 |   4638 batches | lr 0.000113 | ms/batch 428.35 | loss  2.98 | avg loss  2.49 | ppl 12.11\n",
      "| epoch   3 step    46800 |   4738 batches | lr 0.000113 | ms/batch 428.40 | loss  3.03 | avg loss  2.45 | ppl 11.60\n",
      "| epoch   3 step    46900 |   4838 batches | lr 0.000113 | ms/batch 428.30 | loss  2.13 | avg loss  2.50 | ppl 12.23\n",
      "| epoch   3 step    47000 |   4938 batches | lr 0.000113 | ms/batch 428.21 | loss  2.51 | avg loss  2.49 | ppl 12.02\n",
      "| epoch   3 step    47100 |   5038 batches | lr 0.000113 | ms/batch 428.55 | loss  2.14 | avg loss  2.58 | ppl 13.20\n",
      "| epoch   3 step    47200 |   5138 batches | lr 0.000112 | ms/batch 428.59 | loss  3.37 | avg loss  2.56 | ppl 12.89\n",
      "| epoch   3 step    47300 |   5238 batches | lr 0.000112 | ms/batch 428.70 | loss  3.12 | avg loss  2.55 | ppl 12.87\n",
      "| epoch   3 step    47400 |   5338 batches | lr 0.000112 | ms/batch 428.56 | loss  2.21 | avg loss  2.49 | ppl 12.07\n",
      "| epoch   3 step    47500 |   5438 batches | lr 0.000112 | ms/batch 428.59 | loss  2.50 | avg loss  2.53 | ppl 12.52\n",
      "| epoch   3 step    47600 |   5538 batches | lr 0.000112 | ms/batch 428.57 | loss  2.69 | avg loss  2.42 | ppl 11.25\n",
      "| epoch   3 step    47700 |   5638 batches | lr 0.000111 | ms/batch 429.35 | loss  2.48 | avg loss  2.55 | ppl 12.76\n",
      "| epoch   3 step    47800 |   5738 batches | lr 0.000111 | ms/batch 428.76 | loss  2.95 | avg loss  2.61 | ppl 13.55\n",
      "| epoch   3 step    47900 |   5838 batches | lr 0.000111 | ms/batch 428.63 | loss  3.76 | avg loss  2.56 | ppl 12.89\n",
      "| epoch   3 step    48000 |   5938 batches | lr 0.000111 | ms/batch 428.50 | loss  2.58 | avg loss  2.52 | ppl 12.39\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.48000.pt\n",
      "eval samples: 0 loss: tensor(1.4199, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0918, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.2777, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8211, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1724, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7052, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0278, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2631, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5081, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.5297, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8868, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5336, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6321, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7861, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6707, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7241, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9152, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7230, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6214, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5480, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.2988, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.1050, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3314, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2150, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4699, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1862, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.3508, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3660, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6896, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0360, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6684, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2651, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0905, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4076, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3069, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6303, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6969, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(1.0307, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.3837, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2512, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3820, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0133, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.4490, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8880, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(1.0315, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9248, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.3006, device='cuda:0')\n",
      "average loss 1.2088436415827233\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  24 at step    48000 | time: 474.89s | valid loss  1.21 | valid ppl  3.35 | best ppl  3.35 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    48100 |   6038 batches | lr 0.000111 | ms/batch 5177.43 | loss  1.81 | avg loss  2.57 | ppl 13.09\n",
      "| epoch   3 step    48200 |   6138 batches | lr 0.00011 | ms/batch 428.59 | loss  3.17 | avg loss  2.50 | ppl 12.14\n",
      "| epoch   3 step    48300 |   6238 batches | lr 0.00011 | ms/batch 428.45 | loss  2.45 | avg loss  2.52 | ppl 12.40\n",
      "| epoch   3 step    48400 |   6338 batches | lr 0.00011 | ms/batch 428.55 | loss  2.98 | avg loss  2.61 | ppl 13.61\n",
      "| epoch   3 step    48500 |   6438 batches | lr 0.00011 | ms/batch 428.37 | loss  2.03 | avg loss  2.54 | ppl 12.69\n",
      "| epoch   3 step    48600 |   6538 batches | lr 0.00011 | ms/batch 428.31 | loss  2.19 | avg loss  2.44 | ppl 11.47\n",
      "| epoch   3 step    48700 |   6638 batches | lr 0.000109 | ms/batch 428.13 | loss  2.49 | avg loss  2.54 | ppl 12.73\n",
      "| epoch   3 step    48800 |   6738 batches | lr 0.000109 | ms/batch 428.07 | loss  2.29 | avg loss  2.57 | ppl 13.03\n",
      "| epoch   3 step    48900 |   6838 batches | lr 0.000109 | ms/batch 429.01 | loss  3.47 | avg loss  2.48 | ppl 11.98\n",
      "| epoch   3 step    49000 |   6938 batches | lr 0.000109 | ms/batch 428.58 | loss  2.01 | avg loss  2.55 | ppl 12.82\n",
      "| epoch   3 step    49100 |   7038 batches | lr 0.000109 | ms/batch 428.50 | loss  2.26 | avg loss  2.53 | ppl 12.54\n",
      "| epoch   3 step    49200 |   7138 batches | lr 0.000108 | ms/batch 428.27 | loss  2.38 | avg loss  2.60 | ppl 13.44\n",
      "| epoch   3 step    49300 |   7238 batches | lr 0.000108 | ms/batch 428.57 | loss  2.49 | avg loss  2.47 | ppl 11.82\n",
      "| epoch   3 step    49400 |   7338 batches | lr 0.000108 | ms/batch 428.10 | loss  2.18 | avg loss  2.49 | ppl 12.07\n",
      "| epoch   3 step    49500 |   7438 batches | lr 0.000108 | ms/batch 428.09 | loss  2.12 | avg loss  2.52 | ppl 12.49\n",
      "| epoch   3 step    49600 |   7538 batches | lr 0.000108 | ms/batch 428.32 | loss  3.03 | avg loss  2.52 | ppl 12.43\n",
      "| epoch   3 step    49700 |   7638 batches | lr 0.000108 | ms/batch 428.30 | loss  2.47 | avg loss  2.50 | ppl 12.22\n",
      "| epoch   3 step    49800 |   7738 batches | lr 0.000107 | ms/batch 428.28 | loss  2.56 | avg loss  2.59 | ppl 13.27\n",
      "| epoch   3 step    49900 |   7838 batches | lr 0.000107 | ms/batch 428.36 | loss  1.98 | avg loss  2.54 | ppl 12.64\n",
      "| epoch   3 step    50000 |   7938 batches | lr 0.000107 | ms/batch 428.59 | loss  2.72 | avg loss  2.54 | ppl 12.62\n",
      "eval samples: 0 loss: tensor(1.3724, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0676, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.2797, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8344, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1388, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6828, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(0.9924, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2774, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5749, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4569, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8749, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5504, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6216, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7328, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5199, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7245, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(1.0531, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.6806, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.5879, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5012, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3137, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0742, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.2333, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.0991, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4681, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1622, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2241, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3830, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6887, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9744, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6400, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.1645, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1079, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4048, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3279, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6304, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6525, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9919, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.3877, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2159, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3053, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0572, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3141, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8826, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9301, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9179, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2736, device='cuda:0')\n",
      "average loss 1.193908354841581\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  25 at step    50000 | time: 474.64s | valid loss  1.19 | valid ppl  3.30 | best ppl  3.30 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    50100 |   8038 batches | lr 0.000107 | ms/batch 5174.74 | loss  2.50 | avg loss  2.49 | ppl 12.04\n",
      "| epoch   3 step    50200 |   8138 batches | lr 0.000107 | ms/batch 428.38 | loss  2.81 | avg loss  2.54 | ppl 12.62\n",
      "| epoch   3 step    50300 |   8238 batches | lr 0.000106 | ms/batch 428.29 | loss  3.34 | avg loss  2.50 | ppl 12.15\n",
      "| epoch   3 step    50400 |   8338 batches | lr 0.000106 | ms/batch 428.43 | loss  2.40 | avg loss  2.57 | ppl 13.02\n",
      "| epoch   3 step    50500 |   8438 batches | lr 0.000106 | ms/batch 428.44 | loss  2.71 | avg loss  2.57 | ppl 13.08\n",
      "| epoch   3 step    50600 |   8538 batches | lr 0.000106 | ms/batch 428.33 | loss  2.54 | avg loss  2.50 | ppl 12.19\n",
      "| epoch   3 step    50700 |   8638 batches | lr 0.000106 | ms/batch 428.45 | loss  2.26 | avg loss  2.47 | ppl 11.86\n",
      "| epoch   3 step    50800 |   8738 batches | lr 0.000105 | ms/batch 428.45 | loss  2.27 | avg loss  2.49 | ppl 12.08\n",
      "| epoch   3 step    50900 |   8838 batches | lr 0.000105 | ms/batch 428.34 | loss  2.12 | avg loss  2.52 | ppl 12.38\n",
      "| epoch   3 step    51000 |   8938 batches | lr 0.000105 | ms/batch 428.33 | loss  2.18 | avg loss  2.59 | ppl 13.29\n",
      "| epoch   3 step    51100 |   9038 batches | lr 0.000105 | ms/batch 428.35 | loss  1.79 | avg loss  2.52 | ppl 12.44\n",
      "| epoch   3 step    51200 |   9138 batches | lr 0.000105 | ms/batch 428.23 | loss  1.89 | avg loss  2.50 | ppl 12.23\n",
      "| epoch   3 step    51300 |   9238 batches | lr 0.000104 | ms/batch 428.37 | loss  2.12 | avg loss  2.49 | ppl 12.06\n",
      "| epoch   3 step    51400 |   9338 batches | lr 0.000104 | ms/batch 428.35 | loss  2.12 | avg loss  2.50 | ppl 12.16\n",
      "| epoch   3 step    51500 |   9438 batches | lr 0.000104 | ms/batch 428.15 | loss  2.54 | avg loss  2.51 | ppl 12.34\n",
      "| epoch   3 step    51600 |   9538 batches | lr 0.000104 | ms/batch 428.36 | loss  2.32 | avg loss  2.50 | ppl 12.17\n",
      "| epoch   3 step    51700 |   9638 batches | lr 0.000104 | ms/batch 428.29 | loss  2.13 | avg loss  2.57 | ppl 13.11\n",
      "| epoch   3 step    51800 |   9738 batches | lr 0.000103 | ms/batch 428.08 | loss  2.73 | avg loss  2.49 | ppl 12.01\n",
      "| epoch   3 step    51900 |   9838 batches | lr 0.000103 | ms/batch 428.35 | loss  2.41 | avg loss  2.53 | ppl 12.53\n",
      "| epoch   3 step    52000 |   9938 batches | lr 0.000103 | ms/batch 428.46 | loss  2.75 | avg loss  2.54 | ppl 12.71\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.52000.pt\n",
      "eval samples: 0 loss: tensor(1.4221, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0737, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.2781, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8367, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1747, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.7089, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0934, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.3022, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5195, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4553, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9036, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5699, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6192, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7693, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5686, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7302, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(1.0291, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.6765, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6977, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5985, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3078, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0743, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.2772, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1300, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4765, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1246, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2589, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3752, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6923, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0171, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6340, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2671, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1682, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.3964, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3117, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6114, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6754, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9534, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.3620, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2285, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3312, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0468, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3210, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9473, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9569, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9676, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2187, device='cuda:0')\n",
      "average loss 1.2078421120468068\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  26 at step    52000 | time: 474.62s | valid loss  1.21 | valid ppl  3.35 | best ppl  3.30 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    52100 |  10038 batches | lr 0.000103 | ms/batch 5174.51 | loss  2.12 | avg loss  2.46 | ppl 11.73\n",
      "| epoch   3 step    52200 |  10138 batches | lr 0.000103 | ms/batch 428.52 | loss  2.32 | avg loss  2.46 | ppl 11.75\n",
      "| epoch   3 step    52300 |  10238 batches | lr 0.000102 | ms/batch 428.34 | loss  2.74 | avg loss  2.52 | ppl 12.38\n",
      "| epoch   3 step    52400 |  10338 batches | lr 0.000102 | ms/batch 428.12 | loss  2.54 | avg loss  2.47 | ppl 11.84\n",
      "| epoch   3 step    52500 |  10438 batches | lr 0.000102 | ms/batch 428.36 | loss  3.01 | avg loss  2.53 | ppl 12.61\n",
      "| epoch   3 step    52600 |  10538 batches | lr 0.000102 | ms/batch 428.41 | loss  2.55 | avg loss  2.54 | ppl 12.74\n",
      "| epoch   3 step    52700 |  10638 batches | lr 0.000102 | ms/batch 428.28 | loss  3.12 | avg loss  2.57 | ppl 13.09\n",
      "| epoch   3 step    52800 |  10738 batches | lr 0.000102 | ms/batch 428.31 | loss  3.58 | avg loss  2.51 | ppl 12.25\n",
      "| epoch   3 step    52900 |  10838 batches | lr 0.000101 | ms/batch 428.43 | loss  2.93 | avg loss  2.51 | ppl 12.36\n",
      "| epoch   3 step    53000 |  10938 batches | lr 0.000101 | ms/batch 428.32 | loss  2.77 | avg loss  2.57 | ppl 13.10\n",
      "| epoch   3 step    53100 |  11038 batches | lr 0.000101 | ms/batch 428.40 | loss  2.39 | avg loss  2.52 | ppl 12.47\n",
      "| epoch   3 step    53200 |  11138 batches | lr 0.000101 | ms/batch 428.41 | loss  3.05 | avg loss  2.52 | ppl 12.47\n",
      "| epoch   3 step    53300 |  11238 batches | lr 0.000101 | ms/batch 428.49 | loss  2.28 | avg loss  2.52 | ppl 12.41\n",
      "| epoch   3 step    53400 |  11338 batches | lr 0.0001 | ms/batch 428.43 | loss  2.48 | avg loss  2.53 | ppl 12.51\n",
      "| epoch   3 step    53500 |  11438 batches | lr 0.0001 | ms/batch 428.42 | loss  2.43 | avg loss  2.46 | ppl 11.68\n",
      "| epoch   3 step    53600 |  11538 batches | lr 0.0001 | ms/batch 428.48 | loss  2.21 | avg loss  2.50 | ppl 12.23\n",
      "| epoch   3 step    53700 |  11638 batches | lr 9.98e-05 | ms/batch 428.45 | loss  2.06 | avg loss  2.53 | ppl 12.60\n",
      "| epoch   3 step    53800 |  11738 batches | lr 9.96e-05 | ms/batch 428.32 | loss  2.92 | avg loss  2.49 | ppl 12.05\n",
      "| epoch   3 step    53900 |  11838 batches | lr 9.94e-05 | ms/batch 428.39 | loss  2.62 | avg loss  2.50 | ppl 12.19\n",
      "| epoch   3 step    54000 |  11938 batches | lr 9.92e-05 | ms/batch 428.45 | loss  2.31 | avg loss  2.52 | ppl 12.38\n",
      "eval samples: 0 loss: tensor(1.4500, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0027, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.2929, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8248, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2330, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6843, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0359, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.1995, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.4955, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4671, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8207, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5363, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6158, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7306, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6090, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7240, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(1.0049, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.6433, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6209, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5287, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.2959, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0507, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3212, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.0622, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4520, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.0836, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2491, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3904, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7047, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(1.0566, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6321, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2446, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1584, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4271, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.4046, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6379, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6282, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9657, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.3965, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2883, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3644, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.1193, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.2822, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8937, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9644, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9569, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2585, device='cuda:0')\n",
      "average loss 1.2001472152195463\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  27 at step    54000 | time: 474.84s | valid loss  1.20 | valid ppl  3.32 | best ppl  3.30 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    54100 |  12038 batches | lr 9.9e-05 | ms/batch 5176.98 | loss  2.26 | avg loss  2.50 | ppl 12.17\n",
      "| epoch   3 step    54200 |  12138 batches | lr 9.88e-05 | ms/batch 428.45 | loss  2.20 | avg loss  2.51 | ppl 12.29\n",
      "| epoch   3 step    54300 |  12238 batches | lr 9.86e-05 | ms/batch 428.63 | loss  2.47 | avg loss  2.52 | ppl 12.48\n",
      "| epoch   3 step    54400 |  12338 batches | lr 9.84e-05 | ms/batch 428.94 | loss  2.46 | avg loss  2.47 | ppl 11.83\n",
      "| epoch   3 step    54500 |  12438 batches | lr 9.82e-05 | ms/batch 428.94 | loss  2.07 | avg loss  2.52 | ppl 12.47\n",
      "| epoch   3 step    54600 |  12538 batches | lr 9.8e-05 | ms/batch 428.93 | loss  3.30 | avg loss  2.57 | ppl 13.05\n",
      "| epoch   3 step    54700 |  12638 batches | lr 9.78e-05 | ms/batch 428.87 | loss  2.80 | avg loss  2.56 | ppl 12.94\n",
      "| epoch   3 step    54800 |  12738 batches | lr 9.76e-05 | ms/batch 428.75 | loss  2.30 | avg loss  2.52 | ppl 12.49\n",
      "| epoch   3 step    54900 |  12838 batches | lr 9.74e-05 | ms/batch 428.91 | loss  2.37 | avg loss  2.51 | ppl 12.28\n",
      "| epoch   3 step    55000 |  12938 batches | lr 9.72e-05 | ms/batch 428.78 | loss  2.50 | avg loss  2.47 | ppl 11.86\n",
      "| epoch   3 step    55100 |  13038 batches | lr 9.7e-05 | ms/batch 428.83 | loss  2.98 | avg loss  2.52 | ppl 12.49\n",
      "| epoch   3 step    55200 |  13138 batches | lr 9.69e-05 | ms/batch 428.63 | loss  2.83 | avg loss  2.54 | ppl 12.64\n",
      "| epoch   3 step    55300 |  13238 batches | lr 9.67e-05 | ms/batch 428.73 | loss  2.20 | avg loss  2.52 | ppl 12.42\n",
      "| epoch   3 step    55400 |  13338 batches | lr 9.65e-05 | ms/batch 428.79 | loss  2.52 | avg loss  2.60 | ppl 13.41\n",
      "| epoch   3 step    55500 |  13438 batches | lr 9.63e-05 | ms/batch 428.68 | loss  2.48 | avg loss  2.47 | ppl 11.78\n",
      "| epoch   3 step    55600 |  13538 batches | lr 9.61e-05 | ms/batch 428.78 | loss  2.45 | avg loss  2.55 | ppl 12.82\n",
      "| epoch   3 step    55700 |  13638 batches | lr 9.59e-05 | ms/batch 428.73 | loss  2.90 | avg loss  2.61 | ppl 13.54\n",
      "| epoch   3 step    55800 |  13738 batches | lr 9.57e-05 | ms/batch 428.72 | loss  2.42 | avg loss  2.52 | ppl 12.41\n",
      "| epoch   3 step    55900 |  13838 batches | lr 9.55e-05 | ms/batch 428.74 | loss  2.58 | avg loss  2.50 | ppl 12.20\n",
      "| epoch   3 step    56000 |  13938 batches | lr 9.53e-05 | ms/batch 429.18 | loss  3.01 | avg loss  2.51 | ppl 12.29\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.56000.pt\n",
      "eval samples: 0 loss: tensor(1.4277, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0539, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.2745, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.9012, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1542, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6800, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(0.9913, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2680, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5883, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4455, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8503, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5634, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6414, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.6884, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6002, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7056, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9272, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.6595, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6012, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.4742, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.2953, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0558, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3089, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.0903, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4021, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1407, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2566, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3976, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.6926, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9846, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6188, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2184, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.1729, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.3926, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3157, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6079, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6317, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9292, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.3800, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.2085, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3701, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0601, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3314, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9129, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9229, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9375, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2570, device='cuda:0')\n",
      "average loss 1.196097243334843\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  28 at step    56000 | time: 475.15s | valid loss  1.20 | valid ppl  3.31 | best ppl  3.30 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    56100 |  14038 batches | lr 9.51e-05 | ms/batch 5181.14 | loss  2.42 | avg loss  2.50 | ppl 12.16\n",
      "| epoch   3 step    56200 |  14138 batches | lr 9.49e-05 | ms/batch 429.56 | loss  3.08 | avg loss  2.51 | ppl 12.27\n",
      "| epoch   3 step    56300 |  14238 batches | lr 9.47e-05 | ms/batch 429.43 | loss  2.28 | avg loss  2.51 | ppl 12.29\n",
      "| epoch   3 step    56400 |  14338 batches | lr 9.45e-05 | ms/batch 429.33 | loss  2.20 | avg loss  2.60 | ppl 13.46\n",
      "| epoch   3 step    56500 |  14438 batches | lr 9.43e-05 | ms/batch 429.14 | loss  2.46 | avg loss  2.52 | ppl 12.47\n",
      "| epoch   3 step    56600 |  14538 batches | lr 9.41e-05 | ms/batch 429.44 | loss  2.56 | avg loss  2.55 | ppl 12.75\n",
      "| epoch   3 step    56700 |  14638 batches | lr 9.39e-05 | ms/batch 428.77 | loss  2.03 | avg loss  2.47 | ppl 11.82\n",
      "| epoch   3 step    56800 |  14738 batches | lr 9.38e-05 | ms/batch 428.92 | loss  2.66 | avg loss  2.44 | ppl 11.51\n",
      "| epoch   3 step    56900 |  14838 batches | lr 9.36e-05 | ms/batch 429.24 | loss  2.47 | avg loss  2.50 | ppl 12.20\n",
      "| epoch   3 step    57000 |  14938 batches | lr 9.34e-05 | ms/batch 429.56 | loss  2.26 | avg loss  2.52 | ppl 12.48\n",
      "| epoch   3 step    57100 |  15038 batches | lr 9.32e-05 | ms/batch 429.63 | loss  2.64 | avg loss  2.55 | ppl 12.79\n",
      "| epoch   3 step    57200 |  15138 batches | lr 9.3e-05 | ms/batch 429.56 | loss  2.67 | avg loss  2.50 | ppl 12.19\n",
      "| epoch   3 step    57300 |  15238 batches | lr 9.28e-05 | ms/batch 428.73 | loss  2.99 | avg loss  2.52 | ppl 12.41\n",
      "| epoch   3 step    57400 |  15338 batches | lr 9.26e-05 | ms/batch 428.80 | loss  2.97 | avg loss  2.55 | ppl 12.80\n",
      "| epoch   3 step    57500 |  15438 batches | lr 9.24e-05 | ms/batch 428.79 | loss  2.83 | avg loss  2.52 | ppl 12.49\n",
      "| epoch   3 step    57600 |  15538 batches | lr 9.22e-05 | ms/batch 428.80 | loss  3.09 | avg loss  2.55 | ppl 12.83\n",
      "| epoch   3 step    57700 |  15638 batches | lr 9.2e-05 | ms/batch 428.88 | loss  2.55 | avg loss  2.50 | ppl 12.23\n",
      "| epoch   3 step    57800 |  15738 batches | lr 9.18e-05 | ms/batch 428.78 | loss  2.99 | avg loss  2.57 | ppl 13.09\n",
      "| epoch   3 step    57900 |  15838 batches | lr 9.16e-05 | ms/batch 428.80 | loss  2.21 | avg loss  2.54 | ppl 12.72\n",
      "| epoch   3 step    58000 |  15938 batches | lr 9.14e-05 | ms/batch 428.65 | loss  2.55 | avg loss  2.55 | ppl 12.84\n",
      "eval samples: 0 loss: tensor(1.3801, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0360, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.3028, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8727, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.2048, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6985, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0482, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.1706, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.6179, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4312, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.8882, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5666, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6093, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7759, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.6684, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7537, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(1.0511, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.6889, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6633, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5505, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.3008, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0562, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.3119, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.1485, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4458, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1511, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2638, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3864, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7311, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9721, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6540, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.1500, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.0905, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4354, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3704, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6593, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.5970, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9763, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.3970, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1978, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3609, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0680, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3436, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.8578, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9586, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.9094, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2910, device='cuda:0')\n",
      "average loss 1.1968870485099414\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  29 at step    58000 | time: 474.85s | valid loss  1.20 | valid ppl  3.31 | best ppl  3.30 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    58100 |  16038 batches | lr 9.12e-05 | ms/batch 5177.05 | loss  2.41 | avg loss  2.46 | ppl 11.74\n",
      "| epoch   3 step    58200 |  16138 batches | lr 9.1e-05 | ms/batch 428.88 | loss  2.53 | avg loss  2.57 | ppl 13.11\n",
      "| epoch   3 step    58300 |  16238 batches | lr 9.08e-05 | ms/batch 428.75 | loss  2.50 | avg loss  2.52 | ppl 12.46\n",
      "| epoch   3 step    58400 |  16338 batches | lr 9.06e-05 | ms/batch 428.66 | loss  2.42 | avg loss  2.53 | ppl 12.57\n",
      "| epoch   3 step    58500 |  16438 batches | lr 9.05e-05 | ms/batch 428.69 | loss  2.38 | avg loss  2.48 | ppl 11.91\n",
      "| epoch   3 step    58600 |  16538 batches | lr 9.03e-05 | ms/batch 428.82 | loss  2.46 | avg loss  2.55 | ppl 12.87\n",
      "| epoch   3 step    58700 |  16638 batches | lr 9.01e-05 | ms/batch 428.80 | loss  3.05 | avg loss  2.55 | ppl 12.77\n",
      "| epoch   3 step    58800 |  16738 batches | lr 8.99e-05 | ms/batch 428.75 | loss  2.30 | avg loss  2.57 | ppl 13.03\n",
      "| epoch   3 step    58900 |  16838 batches | lr 8.97e-05 | ms/batch 428.62 | loss  2.15 | avg loss  2.49 | ppl 12.08\n",
      "| epoch   3 step    59000 |  16938 batches | lr 8.95e-05 | ms/batch 428.72 | loss  2.58 | avg loss  2.51 | ppl 12.27\n",
      "| epoch   3 step    59100 |  17038 batches | lr 8.93e-05 | ms/batch 428.52 | loss  2.32 | avg loss  2.56 | ppl 12.90\n",
      "| epoch   3 step    59200 |  17138 batches | lr 8.91e-05 | ms/batch 428.62 | loss  2.24 | avg loss  2.46 | ppl 11.70\n",
      "| epoch   3 step    59300 |  17238 batches | lr 8.89e-05 | ms/batch 428.69 | loss  3.07 | avg loss  2.53 | ppl 12.53\n",
      "| epoch   3 step    59400 |  17338 batches | lr 8.87e-05 | ms/batch 428.80 | loss  2.22 | avg loss  2.55 | ppl 12.84\n",
      "| epoch   3 step    59500 |  17438 batches | lr 8.85e-05 | ms/batch 428.77 | loss  2.55 | avg loss  2.51 | ppl 12.32\n",
      "| epoch   3 step    59600 |  17538 batches | lr 8.83e-05 | ms/batch 428.81 | loss  1.93 | avg loss  2.46 | ppl 11.70\n",
      "| epoch   3 step    59700 |  17638 batches | lr 8.81e-05 | ms/batch 428.82 | loss  2.26 | avg loss  2.46 | ppl 11.69\n",
      "| epoch   3 step    59800 |  17738 batches | lr 8.79e-05 | ms/batch 428.93 | loss  2.72 | avg loss  2.52 | ppl 12.43\n",
      "| epoch   3 step    59900 |  17838 batches | lr 8.77e-05 | ms/batch 428.75 | loss  2.82 | avg loss  2.48 | ppl 11.94\n",
      "| epoch   3 step    60000 |  17938 batches | lr 8.75e-05 | ms/batch 428.88 | loss  3.28 | avg loss  2.50 | ppl 12.23\n",
      "saving checkpoint ./trained_models/GPT2_M/e2e_seed110_full/model.60000.pt\n",
      "eval samples: 0 loss: tensor(1.3985, device='cuda:0')\n",
      "eval samples: 100 loss: tensor(1.0609, device='cuda:0')\n",
      "eval samples: 200 loss: tensor(0.2878, device='cuda:0')\n",
      "eval samples: 300 loss: tensor(0.8653, device='cuda:0')\n",
      "eval samples: 400 loss: tensor(1.1819, device='cuda:0')\n",
      "eval samples: 500 loss: tensor(0.6732, device='cuda:0')\n",
      "eval samples: 600 loss: tensor(1.0431, device='cuda:0')\n",
      "eval samples: 700 loss: tensor(1.2549, device='cuda:0')\n",
      "eval samples: 800 loss: tensor(1.5482, device='cuda:0')\n",
      "eval samples: 900 loss: tensor(2.4592, device='cuda:0')\n",
      "eval samples: 1000 loss: tensor(0.9223, device='cuda:0')\n",
      "eval samples: 1100 loss: tensor(0.5777, device='cuda:0')\n",
      "eval samples: 1200 loss: tensor(0.6388, device='cuda:0')\n",
      "eval samples: 1300 loss: tensor(0.7282, device='cuda:0')\n",
      "eval samples: 1400 loss: tensor(1.5525, device='cuda:0')\n",
      "eval samples: 1500 loss: tensor(0.7504, device='cuda:0')\n",
      "eval samples: 1600 loss: tensor(0.9834, device='cuda:0')\n",
      "eval samples: 1700 loss: tensor(1.7110, device='cuda:0')\n",
      "eval samples: 1800 loss: tensor(0.6168, device='cuda:0')\n",
      "eval samples: 1900 loss: tensor(1.5235, device='cuda:0')\n",
      "eval samples: 2000 loss: tensor(0.2835, device='cuda:0')\n",
      "eval samples: 2100 loss: tensor(1.0391, device='cuda:0')\n",
      "eval samples: 2200 loss: tensor(1.2963, device='cuda:0')\n",
      "eval samples: 2300 loss: tensor(2.2017, device='cuda:0')\n",
      "eval samples: 2400 loss: tensor(1.4822, device='cuda:0')\n",
      "eval samples: 2500 loss: tensor(1.1165, device='cuda:0')\n",
      "eval samples: 2600 loss: tensor(1.2144, device='cuda:0')\n",
      "eval samples: 2700 loss: tensor(1.3818, device='cuda:0')\n",
      "eval samples: 2800 loss: tensor(0.7019, device='cuda:0')\n",
      "eval samples: 2900 loss: tensor(0.9647, device='cuda:0')\n",
      "eval samples: 3000 loss: tensor(0.6329, device='cuda:0')\n",
      "eval samples: 3100 loss: tensor(1.2765, device='cuda:0')\n",
      "eval samples: 3200 loss: tensor(1.2122, device='cuda:0')\n",
      "eval samples: 3300 loss: tensor(1.4234, device='cuda:0')\n",
      "eval samples: 3400 loss: tensor(0.3513, device='cuda:0')\n",
      "eval samples: 3500 loss: tensor(0.6442, device='cuda:0')\n",
      "eval samples: 3600 loss: tensor(2.6198, device='cuda:0')\n",
      "eval samples: 3700 loss: tensor(0.9139, device='cuda:0')\n",
      "eval samples: 3800 loss: tensor(0.3894, device='cuda:0')\n",
      "eval samples: 3900 loss: tensor(1.1806, device='cuda:0')\n",
      "eval samples: 4000 loss: tensor(1.3705, device='cuda:0')\n",
      "eval samples: 4100 loss: tensor(1.0368, device='cuda:0')\n",
      "eval samples: 4200 loss: tensor(1.3476, device='cuda:0')\n",
      "eval samples: 4300 loss: tensor(0.9930, device='cuda:0')\n",
      "eval samples: 4400 loss: tensor(0.9583, device='cuda:0')\n",
      "eval samples: 4500 loss: tensor(0.8922, device='cuda:0')\n",
      "eval samples: 4600 loss: tensor(2.2664, device='cuda:0')\n",
      "average loss 1.1998361768328571\n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Eval  30 at step    60000 | time: 475.05s | valid loss  1.20 | valid ppl  3.32 | best ppl  3.30 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| epoch   3 step    60100 |  18038 batches | lr 8.74e-05 | ms/batch 5179.26 | loss  2.35 | avg loss  2.54 | ppl 12.63\n",
      "| epoch   3 step    60200 |  18138 batches | lr 8.72e-05 | ms/batch 428.80 | loss  2.33 | avg loss  2.48 | ppl 12.00\n",
      "| epoch   3 step    60300 |  18238 batches | lr 8.7e-05 | ms/batch 428.86 | loss  2.32 | avg loss  2.54 | ppl 12.62\n",
      "| epoch   3 step    60400 |  18338 batches | lr 8.68e-05 | ms/batch 428.85 | loss  2.80 | avg loss  2.62 | ppl 13.72\n",
      "| epoch   3 step    60500 |  18438 batches | lr 8.66e-05 | ms/batch 428.77 | loss  2.15 | avg loss  2.52 | ppl 12.37\n",
      "| epoch   3 step    60600 |  18538 batches | lr 8.64e-05 | ms/batch 428.88 | loss  2.26 | avg loss  2.58 | ppl 13.24\n",
      "| epoch   3 step    60700 |  18638 batches | lr 8.62e-05 | ms/batch 428.66 | loss  2.27 | avg loss  2.64 | ppl 14.00\n",
      "| epoch   3 step    60800 |  18738 batches | lr 8.6e-05 | ms/batch 428.67 | loss  2.61 | avg loss  2.50 | ppl 12.23\n",
      "| epoch   3 step    60900 |  18838 batches | lr 8.58e-05 | ms/batch 429.01 | loss  2.45 | avg loss  2.48 | ppl 12.00\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=1 src/gpt2_ft.py \\\n",
    "  --train_data ./data/e2e/train.jsonl \\\n",
    "  --valid_data ./data/e2e/valid.jsonl \\\n",
    "  --train_batch_size 2 \\\n",
    "  --grad_acc 4 \\\n",
    "  --valid_batch_size 1 \\\n",
    "  --seq_len 512 \\\n",
    "  --model_card gpt2.md \\\n",
    "  --init_checkpoint ./pretrained_checkpoints/gpt2-medium-pytorch_model.bin \\\n",
    "  --platform local \\\n",
    "  --clip 0.0 \\\n",
    "  --lr 0.0002 \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --correct_bias \\\n",
    "  --adam_beta2 0.999 \\\n",
    "  --scheduler linear \\\n",
    "  --warmup_step 2000 \\\n",
    "  --max_epoch 5 \\\n",
    "  --save_interval 4000 \\\n",
    "  --lora_dim 4 \\\n",
    "  --lora_alpha 32 \\\n",
    "  --lora_dropout 0.1 \\\n",
    "  --label_smooth 0.1 \\\n",
    "  --work_dir ./trained_models/GPT2_M/e2e_seed110_full \\\n",
    "  --random_seed 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T00:36:21.203402Z",
     "iopub.status.busy": "2025-12-29T00:36:21.202939Z",
     "iopub.status.idle": "2025-12-29T00:36:21.454459Z",
     "shell.execute_reply": "2025-12-29T00:36:21.453460Z",
     "shell.execute_reply.started": "2025-12-29T00:36:21.203366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.9G\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.12000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.16000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.20000.pt\n",
      "-rw-r--r-- 1 root root 1.5G Dec 29 00:34 model.21031.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.24000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.28000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.32000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.36000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.40000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.4000.pt\n",
      "-rw-r--r-- 1 root root 1.5G Dec 29 00:34 model.42062.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.44000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.48000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.52000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.56000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.60000.pt\n",
      "-rw-r--r-- 1 root root 1.6M Dec 29 00:34 model.8000.pt\n",
      "model.44000.pt\n",
      "model.48000.pt\n",
      "model.52000.pt\n",
      "model.56000.pt\n",
      "model.60000.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh trained_models/GPT2_M/e2e_seed110_full | tail -n 30\n",
    "!ls trained_models/GPT2_M/e2e_seed110_full | grep -E \"model\\.[0-9]+\\.pt\" | sort -V | tail -n 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:31:18.324873Z",
     "iopub.status.busy": "2025-12-29T23:31:18.324556Z",
     "iopub.status.idle": "2025-12-29T23:31:18.566078Z",
     "shell.execute_reply": "2025-12-29T23:31:18.564896Z",
     "shell.execute_reply.started": "2025-12-29T23:31:18.324847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl-project  model_60000.zip\n",
      "/kaggle/working/fl-project/examples/NLG\n",
      "CODE_OF_CONDUCT.md\t\t    eval\t\t    SECURITY.md\n",
      "create_datasets.sh\t\t    figures\t\t    src\n",
      "data\t\t\t\t    LICENSE\t\t    state.db\n",
      "download_pretrained_checkpoints.sh  pretrained_checkpoints  trained_models\n",
      "e2e_pred.txt\t\t\t    README.md\t\t    vocab\n",
      "e2e_ref.txt\t\t\t    requirement.txt\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "%cd fl-project/examples/NLG\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:31:30.760658Z",
     "iopub.status.busy": "2025-12-29T23:31:30.760237Z",
     "iopub.status.idle": "2025-12-29T23:31:30.946269Z",
     "shell.execute_reply": "2025-12-29T23:31:30.945541Z",
     "shell.execute_reply.started": "2025-12-29T23:31:30.760616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model.56000.pt (deflated 8%)\n"
     ]
    }
   ],
   "source": [
    "!zip -j /kaggle/working/model_56000.zip trained_models/GPT2_M/e2e_seed110_full/model.56000.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-29T23:31:38.477171Z",
     "iopub.status.busy": "2025-12-29T23:31:38.476877Z",
     "iopub.status.idle": "2025-12-29T23:31:38.598148Z",
     "shell.execute_reply": "2025-12-29T23:31:38.597198Z",
     "shell.execute_reply.started": "2025-12-29T23:31:38.477145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4693 data/e2e/test.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/e2e/test.jsonl"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
